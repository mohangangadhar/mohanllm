{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.987422438369949,
  "eval_steps": 500,
  "global_step": 7450,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01341606573872212,
      "grad_norm": 19.05977439880371,
      "learning_rate": 9.000000000000001e-07,
      "loss": 0.936,
      "step": 10
    },
    {
      "epoch": 0.02683213147744424,
      "grad_norm": 18.547557830810547,
      "learning_rate": 1.9000000000000002e-06,
      "loss": 0.9648,
      "step": 20
    },
    {
      "epoch": 0.04024819721616636,
      "grad_norm": 17.923141479492188,
      "learning_rate": 2.9e-06,
      "loss": 0.8846,
      "step": 30
    },
    {
      "epoch": 0.05366426295488848,
      "grad_norm": 16.460893630981445,
      "learning_rate": 3.900000000000001e-06,
      "loss": 0.7858,
      "step": 40
    },
    {
      "epoch": 0.0670803286936106,
      "grad_norm": 14.56473445892334,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.5268,
      "step": 50
    },
    {
      "epoch": 0.08049639443233272,
      "grad_norm": 4.871461868286133,
      "learning_rate": 5.9e-06,
      "loss": 0.2283,
      "step": 60
    },
    {
      "epoch": 0.09391246017105484,
      "grad_norm": 1.2897100448608398,
      "learning_rate": 6.9e-06,
      "loss": 0.0953,
      "step": 70
    },
    {
      "epoch": 0.10732852590977696,
      "grad_norm": 0.22847945988178253,
      "learning_rate": 7.9e-06,
      "loss": 0.0561,
      "step": 80
    },
    {
      "epoch": 0.12074459164849907,
      "grad_norm": 0.40033069252967834,
      "learning_rate": 8.900000000000001e-06,
      "loss": 0.0496,
      "step": 90
    },
    {
      "epoch": 0.1341606573872212,
      "grad_norm": 0.29080742597579956,
      "learning_rate": 9.9e-06,
      "loss": 0.0539,
      "step": 100
    },
    {
      "epoch": 0.1475767231259433,
      "grad_norm": 0.3696836829185486,
      "learning_rate": 9.987755102040817e-06,
      "loss": 0.0489,
      "step": 110
    },
    {
      "epoch": 0.16099278886466545,
      "grad_norm": 0.2415374517440796,
      "learning_rate": 9.974149659863947e-06,
      "loss": 0.0483,
      "step": 120
    },
    {
      "epoch": 0.17440885460338756,
      "grad_norm": 0.25772005319595337,
      "learning_rate": 9.960544217687075e-06,
      "loss": 0.0381,
      "step": 130
    },
    {
      "epoch": 0.18782492034210968,
      "grad_norm": 0.2013426274061203,
      "learning_rate": 9.946938775510205e-06,
      "loss": 0.0363,
      "step": 140
    },
    {
      "epoch": 0.2012409860808318,
      "grad_norm": 0.37836170196533203,
      "learning_rate": 9.933333333333334e-06,
      "loss": 0.038,
      "step": 150
    },
    {
      "epoch": 0.2146570518195539,
      "grad_norm": 0.2607828974723816,
      "learning_rate": 9.919727891156464e-06,
      "loss": 0.0275,
      "step": 160
    },
    {
      "epoch": 0.22807311755827603,
      "grad_norm": 0.8865875005722046,
      "learning_rate": 9.906122448979592e-06,
      "loss": 0.0329,
      "step": 170
    },
    {
      "epoch": 0.24148918329699814,
      "grad_norm": 0.2710137367248535,
      "learning_rate": 9.892517006802722e-06,
      "loss": 0.0238,
      "step": 180
    },
    {
      "epoch": 0.25490524903572026,
      "grad_norm": 0.31815871596336365,
      "learning_rate": 9.878911564625852e-06,
      "loss": 0.0175,
      "step": 190
    },
    {
      "epoch": 0.2683213147744424,
      "grad_norm": 0.46074604988098145,
      "learning_rate": 9.86530612244898e-06,
      "loss": 0.011,
      "step": 200
    },
    {
      "epoch": 0.2817373805131645,
      "grad_norm": 0.3420620560646057,
      "learning_rate": 9.85170068027211e-06,
      "loss": 0.0071,
      "step": 210
    },
    {
      "epoch": 0.2951534462518866,
      "grad_norm": 0.5945677161216736,
      "learning_rate": 9.838095238095238e-06,
      "loss": 0.0028,
      "step": 220
    },
    {
      "epoch": 0.3085695119906088,
      "grad_norm": 0.16437958180904388,
      "learning_rate": 9.824489795918368e-06,
      "loss": 0.0017,
      "step": 230
    },
    {
      "epoch": 0.3219855777293309,
      "grad_norm": 0.05226097255945206,
      "learning_rate": 9.810884353741498e-06,
      "loss": 0.0016,
      "step": 240
    },
    {
      "epoch": 0.335401643468053,
      "grad_norm": 0.20370522141456604,
      "learning_rate": 9.797278911564627e-06,
      "loss": 0.0019,
      "step": 250
    },
    {
      "epoch": 0.34881770920677513,
      "grad_norm": 0.28292936086654663,
      "learning_rate": 9.783673469387755e-06,
      "loss": 0.0011,
      "step": 260
    },
    {
      "epoch": 0.36223377494549724,
      "grad_norm": 0.057594433426856995,
      "learning_rate": 9.770068027210885e-06,
      "loss": 0.0018,
      "step": 270
    },
    {
      "epoch": 0.37564984068421936,
      "grad_norm": 0.24326761066913605,
      "learning_rate": 9.756462585034015e-06,
      "loss": 0.0008,
      "step": 280
    },
    {
      "epoch": 0.3890659064229415,
      "grad_norm": 0.06231805309653282,
      "learning_rate": 9.742857142857143e-06,
      "loss": 0.0007,
      "step": 290
    },
    {
      "epoch": 0.4024819721616636,
      "grad_norm": 0.016671564429998398,
      "learning_rate": 9.729251700680273e-06,
      "loss": 0.0006,
      "step": 300
    },
    {
      "epoch": 0.4158980379003857,
      "grad_norm": 0.019773472100496292,
      "learning_rate": 9.715646258503402e-06,
      "loss": 0.0006,
      "step": 310
    },
    {
      "epoch": 0.4293141036391078,
      "grad_norm": 0.5068122148513794,
      "learning_rate": 9.702040816326531e-06,
      "loss": 0.0015,
      "step": 320
    },
    {
      "epoch": 0.44273016937782994,
      "grad_norm": 0.06320410966873169,
      "learning_rate": 9.688435374149661e-06,
      "loss": 0.0006,
      "step": 330
    },
    {
      "epoch": 0.45614623511655206,
      "grad_norm": 0.018854698166251183,
      "learning_rate": 9.67482993197279e-06,
      "loss": 0.0004,
      "step": 340
    },
    {
      "epoch": 0.4695623008552742,
      "grad_norm": 0.24649879336357117,
      "learning_rate": 9.66122448979592e-06,
      "loss": 0.0007,
      "step": 350
    },
    {
      "epoch": 0.4829783665939963,
      "grad_norm": 0.038253627717494965,
      "learning_rate": 9.647619047619048e-06,
      "loss": 0.0006,
      "step": 360
    },
    {
      "epoch": 0.4963944323327184,
      "grad_norm": 0.035690534859895706,
      "learning_rate": 9.634013605442178e-06,
      "loss": 0.0004,
      "step": 370
    },
    {
      "epoch": 0.5098104980714405,
      "grad_norm": 0.019980650395154953,
      "learning_rate": 9.620408163265306e-06,
      "loss": 0.0004,
      "step": 380
    },
    {
      "epoch": 0.5232265638101626,
      "grad_norm": 0.3723899722099304,
      "learning_rate": 9.606802721088436e-06,
      "loss": 0.0007,
      "step": 390
    },
    {
      "epoch": 0.5366426295488848,
      "grad_norm": 0.024672428146004677,
      "learning_rate": 9.593197278911566e-06,
      "loss": 0.0005,
      "step": 400
    },
    {
      "epoch": 0.5500586952876069,
      "grad_norm": 0.015487994067370892,
      "learning_rate": 9.579591836734695e-06,
      "loss": 0.0003,
      "step": 410
    },
    {
      "epoch": 0.563474761026329,
      "grad_norm": 0.43729493021965027,
      "learning_rate": 9.565986394557823e-06,
      "loss": 0.0014,
      "step": 420
    },
    {
      "epoch": 0.5768908267650511,
      "grad_norm": 0.025577746331691742,
      "learning_rate": 9.552380952380953e-06,
      "loss": 0.0002,
      "step": 430
    },
    {
      "epoch": 0.5903068925037732,
      "grad_norm": 0.044290948659181595,
      "learning_rate": 9.538775510204083e-06,
      "loss": 0.0003,
      "step": 440
    },
    {
      "epoch": 0.6037229582424953,
      "grad_norm": 0.1402033567428589,
      "learning_rate": 9.525170068027211e-06,
      "loss": 0.0004,
      "step": 450
    },
    {
      "epoch": 0.6171390239812176,
      "grad_norm": 0.022863347083330154,
      "learning_rate": 9.511564625850341e-06,
      "loss": 0.0004,
      "step": 460
    },
    {
      "epoch": 0.6305550897199397,
      "grad_norm": 0.029589081183075905,
      "learning_rate": 9.49795918367347e-06,
      "loss": 0.0005,
      "step": 470
    },
    {
      "epoch": 0.6439711554586618,
      "grad_norm": 0.1786160171031952,
      "learning_rate": 9.4843537414966e-06,
      "loss": 0.0004,
      "step": 480
    },
    {
      "epoch": 0.6573872211973839,
      "grad_norm": 0.03537018224596977,
      "learning_rate": 9.47074829931973e-06,
      "loss": 0.0003,
      "step": 490
    },
    {
      "epoch": 0.670803286936106,
      "grad_norm": 0.13143491744995117,
      "learning_rate": 9.457142857142858e-06,
      "loss": 0.0003,
      "step": 500
    },
    {
      "epoch": 0.6842193526748281,
      "grad_norm": 0.026578789576888084,
      "learning_rate": 9.443537414965988e-06,
      "loss": 0.0004,
      "step": 510
    },
    {
      "epoch": 0.6976354184135503,
      "grad_norm": 0.011258631944656372,
      "learning_rate": 9.429931972789116e-06,
      "loss": 0.0003,
      "step": 520
    },
    {
      "epoch": 0.7110514841522724,
      "grad_norm": 0.010268539190292358,
      "learning_rate": 9.416326530612246e-06,
      "loss": 0.0003,
      "step": 530
    },
    {
      "epoch": 0.7244675498909945,
      "grad_norm": 0.18915705382823944,
      "learning_rate": 9.402721088435374e-06,
      "loss": 0.0003,
      "step": 540
    },
    {
      "epoch": 0.7378836156297166,
      "grad_norm": 0.017393864691257477,
      "learning_rate": 9.389115646258504e-06,
      "loss": 0.0003,
      "step": 550
    },
    {
      "epoch": 0.7512996813684387,
      "grad_norm": 0.030735349282622337,
      "learning_rate": 9.375510204081634e-06,
      "loss": 0.0002,
      "step": 560
    },
    {
      "epoch": 0.7647157471071608,
      "grad_norm": 0.6392205357551575,
      "learning_rate": 9.361904761904762e-06,
      "loss": 0.0004,
      "step": 570
    },
    {
      "epoch": 0.778131812845883,
      "grad_norm": 0.019625065848231316,
      "learning_rate": 9.34829931972789e-06,
      "loss": 0.0002,
      "step": 580
    },
    {
      "epoch": 0.7915478785846051,
      "grad_norm": 0.005930599756538868,
      "learning_rate": 9.33469387755102e-06,
      "loss": 0.0003,
      "step": 590
    },
    {
      "epoch": 0.8049639443233272,
      "grad_norm": 0.0037382347509264946,
      "learning_rate": 9.32108843537415e-06,
      "loss": 0.0002,
      "step": 600
    },
    {
      "epoch": 0.8183800100620493,
      "grad_norm": 0.019665302708745003,
      "learning_rate": 9.30748299319728e-06,
      "loss": 0.0002,
      "step": 610
    },
    {
      "epoch": 0.8317960758007714,
      "grad_norm": 0.02783871814608574,
      "learning_rate": 9.293877551020409e-06,
      "loss": 0.0003,
      "step": 620
    },
    {
      "epoch": 0.8452121415394935,
      "grad_norm": 0.017224261537194252,
      "learning_rate": 9.280272108843537e-06,
      "loss": 0.0002,
      "step": 630
    },
    {
      "epoch": 0.8586282072782156,
      "grad_norm": 0.00740636233240366,
      "learning_rate": 9.266666666666667e-06,
      "loss": 0.0002,
      "step": 640
    },
    {
      "epoch": 0.8720442730169378,
      "grad_norm": 0.044366732239723206,
      "learning_rate": 9.253061224489797e-06,
      "loss": 0.0006,
      "step": 650
    },
    {
      "epoch": 0.8854603387556599,
      "grad_norm": 0.020684724673628807,
      "learning_rate": 9.239455782312925e-06,
      "loss": 0.0004,
      "step": 660
    },
    {
      "epoch": 0.898876404494382,
      "grad_norm": 0.007698070723563433,
      "learning_rate": 9.225850340136055e-06,
      "loss": 0.0003,
      "step": 670
    },
    {
      "epoch": 0.9122924702331041,
      "grad_norm": 0.021907363086938858,
      "learning_rate": 9.212244897959185e-06,
      "loss": 0.0003,
      "step": 680
    },
    {
      "epoch": 0.9257085359718262,
      "grad_norm": 0.02431662753224373,
      "learning_rate": 9.198639455782314e-06,
      "loss": 0.0003,
      "step": 690
    },
    {
      "epoch": 0.9391246017105483,
      "grad_norm": 0.0036948106717318296,
      "learning_rate": 9.185034013605442e-06,
      "loss": 0.0005,
      "step": 700
    },
    {
      "epoch": 0.9525406674492705,
      "grad_norm": 0.04515879973769188,
      "learning_rate": 9.171428571428572e-06,
      "loss": 0.0002,
      "step": 710
    },
    {
      "epoch": 0.9659567331879926,
      "grad_norm": 0.005777002777904272,
      "learning_rate": 9.157823129251702e-06,
      "loss": 0.0002,
      "step": 720
    },
    {
      "epoch": 0.9793727989267147,
      "grad_norm": 0.007937018759548664,
      "learning_rate": 9.144217687074832e-06,
      "loss": 0.0002,
      "step": 730
    },
    {
      "epoch": 0.9927888646654368,
      "grad_norm": 0.014482732862234116,
      "learning_rate": 9.13061224489796e-06,
      "loss": 0.0002,
      "step": 740
    },
    {
      "epoch": 1.005366426295489,
      "grad_norm": 0.047110024839639664,
      "learning_rate": 9.117006802721088e-06,
      "loss": 0.0002,
      "step": 750
    },
    {
      "epoch": 1.018782492034211,
      "grad_norm": 0.008050440810620785,
      "learning_rate": 9.103401360544218e-06,
      "loss": 0.0002,
      "step": 760
    },
    {
      "epoch": 1.0321985577729331,
      "grad_norm": 0.05147233232855797,
      "learning_rate": 9.089795918367348e-06,
      "loss": 0.0002,
      "step": 770
    },
    {
      "epoch": 1.0456146235116552,
      "grad_norm": 0.005887940060347319,
      "learning_rate": 9.076190476190477e-06,
      "loss": 0.0002,
      "step": 780
    },
    {
      "epoch": 1.0590306892503774,
      "grad_norm": 0.17527133226394653,
      "learning_rate": 9.062585034013605e-06,
      "loss": 0.0003,
      "step": 790
    },
    {
      "epoch": 1.0724467549890995,
      "grad_norm": 0.011110532097518444,
      "learning_rate": 9.048979591836735e-06,
      "loss": 0.0005,
      "step": 800
    },
    {
      "epoch": 1.0858628207278216,
      "grad_norm": 0.00569769274443388,
      "learning_rate": 9.035374149659865e-06,
      "loss": 0.0001,
      "step": 810
    },
    {
      "epoch": 1.0992788864665437,
      "grad_norm": 0.07384642213582993,
      "learning_rate": 9.021768707482993e-06,
      "loss": 0.0002,
      "step": 820
    },
    {
      "epoch": 1.1126949522052658,
      "grad_norm": 0.010386084206402302,
      "learning_rate": 9.008163265306123e-06,
      "loss": 0.0002,
      "step": 830
    },
    {
      "epoch": 1.126111017943988,
      "grad_norm": 0.004000484477728605,
      "learning_rate": 8.994557823129253e-06,
      "loss": 0.0002,
      "step": 840
    },
    {
      "epoch": 1.13952708368271,
      "grad_norm": 0.007218129932880402,
      "learning_rate": 8.980952380952382e-06,
      "loss": 0.0001,
      "step": 850
    },
    {
      "epoch": 1.1529431494214322,
      "grad_norm": 0.016770731657743454,
      "learning_rate": 8.967346938775512e-06,
      "loss": 0.0001,
      "step": 860
    },
    {
      "epoch": 1.1663592151601543,
      "grad_norm": 0.013916009105741978,
      "learning_rate": 8.95374149659864e-06,
      "loss": 0.0002,
      "step": 870
    },
    {
      "epoch": 1.1797752808988764,
      "grad_norm": 0.1141808032989502,
      "learning_rate": 8.94013605442177e-06,
      "loss": 0.0002,
      "step": 880
    },
    {
      "epoch": 1.1931913466375985,
      "grad_norm": 0.02816876396536827,
      "learning_rate": 8.9265306122449e-06,
      "loss": 0.0004,
      "step": 890
    },
    {
      "epoch": 1.2066074123763206,
      "grad_norm": 0.004514380823820829,
      "learning_rate": 8.912925170068028e-06,
      "loss": 0.0002,
      "step": 900
    },
    {
      "epoch": 1.2200234781150427,
      "grad_norm": 0.020444154739379883,
      "learning_rate": 8.899319727891156e-06,
      "loss": 0.0002,
      "step": 910
    },
    {
      "epoch": 1.2334395438537649,
      "grad_norm": 0.009676430374383926,
      "learning_rate": 8.885714285714286e-06,
      "loss": 0.0001,
      "step": 920
    },
    {
      "epoch": 1.246855609592487,
      "grad_norm": 0.011391018517315388,
      "learning_rate": 8.872108843537416e-06,
      "loss": 0.0001,
      "step": 930
    },
    {
      "epoch": 1.260271675331209,
      "grad_norm": 0.02333882637321949,
      "learning_rate": 8.858503401360545e-06,
      "loss": 0.0002,
      "step": 940
    },
    {
      "epoch": 1.2736877410699312,
      "grad_norm": 0.007194815203547478,
      "learning_rate": 8.844897959183673e-06,
      "loss": 0.0001,
      "step": 950
    },
    {
      "epoch": 1.2871038068086533,
      "grad_norm": 0.006208573002368212,
      "learning_rate": 8.831292517006803e-06,
      "loss": 0.0001,
      "step": 960
    },
    {
      "epoch": 1.3005198725473754,
      "grad_norm": 0.011778869666159153,
      "learning_rate": 8.817687074829933e-06,
      "loss": 0.0002,
      "step": 970
    },
    {
      "epoch": 1.3139359382860976,
      "grad_norm": 0.024476131424307823,
      "learning_rate": 8.804081632653063e-06,
      "loss": 0.0001,
      "step": 980
    },
    {
      "epoch": 1.3273520040248197,
      "grad_norm": 0.005477583967149258,
      "learning_rate": 8.790476190476191e-06,
      "loss": 0.0001,
      "step": 990
    },
    {
      "epoch": 1.3407680697635418,
      "grad_norm": 0.012782463803887367,
      "learning_rate": 8.776870748299321e-06,
      "loss": 0.0001,
      "step": 1000
    },
    {
      "epoch": 1.354184135502264,
      "grad_norm": 0.011695705354213715,
      "learning_rate": 8.76326530612245e-06,
      "loss": 0.0001,
      "step": 1010
    },
    {
      "epoch": 1.367600201240986,
      "grad_norm": 0.008146888576447964,
      "learning_rate": 8.74965986394558e-06,
      "loss": 0.0001,
      "step": 1020
    },
    {
      "epoch": 1.3810162669797081,
      "grad_norm": 0.00928364135324955,
      "learning_rate": 8.736054421768708e-06,
      "loss": 0.0001,
      "step": 1030
    },
    {
      "epoch": 1.3944323327184303,
      "grad_norm": 0.0052960896864533424,
      "learning_rate": 8.722448979591838e-06,
      "loss": 0.0001,
      "step": 1040
    },
    {
      "epoch": 1.4078483984571524,
      "grad_norm": 0.019144712015986443,
      "learning_rate": 8.708843537414968e-06,
      "loss": 0.0001,
      "step": 1050
    },
    {
      "epoch": 1.4212644641958745,
      "grad_norm": 0.007635528687387705,
      "learning_rate": 8.695238095238096e-06,
      "loss": 0.0001,
      "step": 1060
    },
    {
      "epoch": 1.4346805299345966,
      "grad_norm": 0.009193656966090202,
      "learning_rate": 8.681632653061224e-06,
      "loss": 0.0001,
      "step": 1070
    },
    {
      "epoch": 1.4480965956733187,
      "grad_norm": 0.031223665922880173,
      "learning_rate": 8.668027210884354e-06,
      "loss": 0.0001,
      "step": 1080
    },
    {
      "epoch": 1.4615126614120408,
      "grad_norm": 0.015303581021726131,
      "learning_rate": 8.654421768707484e-06,
      "loss": 0.0001,
      "step": 1090
    },
    {
      "epoch": 1.474928727150763,
      "grad_norm": 0.1745203137397766,
      "learning_rate": 8.640816326530614e-06,
      "loss": 0.0003,
      "step": 1100
    },
    {
      "epoch": 1.4883447928894853,
      "grad_norm": 0.02482648193836212,
      "learning_rate": 8.627210884353742e-06,
      "loss": 0.0003,
      "step": 1110
    },
    {
      "epoch": 1.5017608586282072,
      "grad_norm": 0.01130027323961258,
      "learning_rate": 8.61360544217687e-06,
      "loss": 0.0001,
      "step": 1120
    },
    {
      "epoch": 1.5151769243669295,
      "grad_norm": 0.011709507554769516,
      "learning_rate": 8.6e-06,
      "loss": 0.0001,
      "step": 1130
    },
    {
      "epoch": 1.5285929901056514,
      "grad_norm": 0.006999696604907513,
      "learning_rate": 8.58639455782313e-06,
      "loss": 0.0004,
      "step": 1140
    },
    {
      "epoch": 1.5420090558443738,
      "grad_norm": 0.003663227893412113,
      "learning_rate": 8.572789115646259e-06,
      "loss": 0.0001,
      "step": 1150
    },
    {
      "epoch": 1.5554251215830956,
      "grad_norm": 0.004106439650058746,
      "learning_rate": 8.559183673469389e-06,
      "loss": 0.0001,
      "step": 1160
    },
    {
      "epoch": 1.568841187321818,
      "grad_norm": 0.005562178790569305,
      "learning_rate": 8.545578231292517e-06,
      "loss": 0.0001,
      "step": 1170
    },
    {
      "epoch": 1.5822572530605399,
      "grad_norm": 0.017724810168147087,
      "learning_rate": 8.531972789115647e-06,
      "loss": 0.0002,
      "step": 1180
    },
    {
      "epoch": 1.5956733187992622,
      "grad_norm": 0.011094450950622559,
      "learning_rate": 8.518367346938775e-06,
      "loss": 0.0002,
      "step": 1190
    },
    {
      "epoch": 1.6090893845379841,
      "grad_norm": 0.0055022756569087505,
      "learning_rate": 8.504761904761905e-06,
      "loss": 0.0001,
      "step": 1200
    },
    {
      "epoch": 1.6225054502767065,
      "grad_norm": 0.001975421095266938,
      "learning_rate": 8.491156462585035e-06,
      "loss": 0.0001,
      "step": 1210
    },
    {
      "epoch": 1.6359215160154283,
      "grad_norm": 0.004462432116270065,
      "learning_rate": 8.477551020408164e-06,
      "loss": 0.0001,
      "step": 1220
    },
    {
      "epoch": 1.6493375817541507,
      "grad_norm": 0.01294791605323553,
      "learning_rate": 8.463945578231294e-06,
      "loss": 0.0001,
      "step": 1230
    },
    {
      "epoch": 1.6627536474928726,
      "grad_norm": 0.018752506002783775,
      "learning_rate": 8.450340136054422e-06,
      "loss": 0.0001,
      "step": 1240
    },
    {
      "epoch": 1.676169713231595,
      "grad_norm": 0.020371107384562492,
      "learning_rate": 8.436734693877552e-06,
      "loss": 0.0002,
      "step": 1250
    },
    {
      "epoch": 1.6895857789703168,
      "grad_norm": 0.011903551407158375,
      "learning_rate": 8.423129251700682e-06,
      "loss": 0.0001,
      "step": 1260
    },
    {
      "epoch": 1.7030018447090391,
      "grad_norm": 0.002708203624933958,
      "learning_rate": 8.40952380952381e-06,
      "loss": 0.0002,
      "step": 1270
    },
    {
      "epoch": 1.716417910447761,
      "grad_norm": 0.023808304220438004,
      "learning_rate": 8.395918367346939e-06,
      "loss": 0.0001,
      "step": 1280
    },
    {
      "epoch": 1.7298339761864834,
      "grad_norm": 0.02387361228466034,
      "learning_rate": 8.382312925170069e-06,
      "loss": 0.0001,
      "step": 1290
    },
    {
      "epoch": 1.7432500419252053,
      "grad_norm": 0.028712555766105652,
      "learning_rate": 8.368707482993198e-06,
      "loss": 0.0002,
      "step": 1300
    },
    {
      "epoch": 1.7566661076639276,
      "grad_norm": 0.0029954651836305857,
      "learning_rate": 8.355102040816327e-06,
      "loss": 0.0001,
      "step": 1310
    },
    {
      "epoch": 1.7700821734026497,
      "grad_norm": 0.005451803095638752,
      "learning_rate": 8.341496598639457e-06,
      "loss": 0.0001,
      "step": 1320
    },
    {
      "epoch": 1.7834982391413718,
      "grad_norm": 0.010255063883960247,
      "learning_rate": 8.327891156462585e-06,
      "loss": 0.0001,
      "step": 1330
    },
    {
      "epoch": 1.796914304880094,
      "grad_norm": 0.0032460230868309736,
      "learning_rate": 8.314285714285715e-06,
      "loss": 0.0001,
      "step": 1340
    },
    {
      "epoch": 1.810330370618816,
      "grad_norm": 0.011611035093665123,
      "learning_rate": 8.300680272108845e-06,
      "loss": 0.0002,
      "step": 1350
    },
    {
      "epoch": 1.8237464363575382,
      "grad_norm": 0.00539614399895072,
      "learning_rate": 8.287074829931973e-06,
      "loss": 0.0001,
      "step": 1360
    },
    {
      "epoch": 1.8371625020962603,
      "grad_norm": 0.008427666500210762,
      "learning_rate": 8.273469387755103e-06,
      "loss": 0.0001,
      "step": 1370
    },
    {
      "epoch": 1.8505785678349824,
      "grad_norm": 0.011473619379103184,
      "learning_rate": 8.259863945578232e-06,
      "loss": 0.0001,
      "step": 1380
    },
    {
      "epoch": 1.8639946335737045,
      "grad_norm": 0.005167489871382713,
      "learning_rate": 8.246258503401362e-06,
      "loss": 0.0001,
      "step": 1390
    },
    {
      "epoch": 1.8774106993124267,
      "grad_norm": 0.007479160092771053,
      "learning_rate": 8.23265306122449e-06,
      "loss": 0.0001,
      "step": 1400
    },
    {
      "epoch": 1.8908267650511488,
      "grad_norm": 0.0037053306587040424,
      "learning_rate": 8.21904761904762e-06,
      "loss": 0.0001,
      "step": 1410
    },
    {
      "epoch": 1.9042428307898709,
      "grad_norm": 0.011526999063789845,
      "learning_rate": 8.20544217687075e-06,
      "loss": 0.0001,
      "step": 1420
    },
    {
      "epoch": 1.917658896528593,
      "grad_norm": 0.003202748252078891,
      "learning_rate": 8.191836734693878e-06,
      "loss": 0.0001,
      "step": 1430
    },
    {
      "epoch": 1.9310749622673151,
      "grad_norm": 0.010223372839391232,
      "learning_rate": 8.178231292517006e-06,
      "loss": 0.0001,
      "step": 1440
    },
    {
      "epoch": 1.9444910280060372,
      "grad_norm": 0.0037005445919930935,
      "learning_rate": 8.164625850340136e-06,
      "loss": 0.0001,
      "step": 1450
    },
    {
      "epoch": 1.9579070937447594,
      "grad_norm": 0.019383475184440613,
      "learning_rate": 8.151020408163266e-06,
      "loss": 0.0001,
      "step": 1460
    },
    {
      "epoch": 1.9713231594834815,
      "grad_norm": 0.0056510670110583305,
      "learning_rate": 8.137414965986395e-06,
      "loss": 0.0001,
      "step": 1470
    },
    {
      "epoch": 1.9847392252222036,
      "grad_norm": 0.05822066217660904,
      "learning_rate": 8.123809523809525e-06,
      "loss": 0.0001,
      "step": 1480
    },
    {
      "epoch": 1.9981552909609257,
      "grad_norm": 0.003958414308726788,
      "learning_rate": 8.110204081632653e-06,
      "loss": 0.0001,
      "step": 1490
    },
    {
      "epoch": 2.010732852590978,
      "grad_norm": 0.025448109954595566,
      "learning_rate": 8.096598639455783e-06,
      "loss": 0.0001,
      "step": 1500
    },
    {
      "epoch": 2.0241489183296997,
      "grad_norm": 0.0030723854433745146,
      "learning_rate": 8.082993197278913e-06,
      "loss": 0.0001,
      "step": 1510
    },
    {
      "epoch": 2.037564984068422,
      "grad_norm": 0.002600296400487423,
      "learning_rate": 8.069387755102041e-06,
      "loss": 0.0001,
      "step": 1520
    },
    {
      "epoch": 2.050981049807144,
      "grad_norm": 0.0070402612909674644,
      "learning_rate": 8.055782312925171e-06,
      "loss": 0.0001,
      "step": 1530
    },
    {
      "epoch": 2.0643971155458662,
      "grad_norm": 0.002088760258629918,
      "learning_rate": 8.0421768707483e-06,
      "loss": 0.0001,
      "step": 1540
    },
    {
      "epoch": 2.077813181284588,
      "grad_norm": 0.0070160324685275555,
      "learning_rate": 8.02857142857143e-06,
      "loss": 0.0001,
      "step": 1550
    },
    {
      "epoch": 2.0912292470233105,
      "grad_norm": 0.00225120154209435,
      "learning_rate": 8.014965986394558e-06,
      "loss": 0.0001,
      "step": 1560
    },
    {
      "epoch": 2.1046453127620324,
      "grad_norm": 0.010483924299478531,
      "learning_rate": 8.001360544217688e-06,
      "loss": 0.0001,
      "step": 1570
    },
    {
      "epoch": 2.1180613785007547,
      "grad_norm": 0.00829342845827341,
      "learning_rate": 7.987755102040818e-06,
      "loss": 0.0001,
      "step": 1580
    },
    {
      "epoch": 2.1314774442394766,
      "grad_norm": 0.0138935511931777,
      "learning_rate": 7.974149659863946e-06,
      "loss": 0.0001,
      "step": 1590
    },
    {
      "epoch": 2.144893509978199,
      "grad_norm": 0.0024253230076283216,
      "learning_rate": 7.960544217687076e-06,
      "loss": 0.0001,
      "step": 1600
    },
    {
      "epoch": 2.158309575716921,
      "grad_norm": 0.003103776602074504,
      "learning_rate": 7.946938775510204e-06,
      "loss": 0.0001,
      "step": 1610
    },
    {
      "epoch": 2.171725641455643,
      "grad_norm": 0.0032124791759997606,
      "learning_rate": 7.933333333333334e-06,
      "loss": 0.0001,
      "step": 1620
    },
    {
      "epoch": 2.185141707194365,
      "grad_norm": 0.007970090955495834,
      "learning_rate": 7.919727891156464e-06,
      "loss": 0.0001,
      "step": 1630
    },
    {
      "epoch": 2.1985577729330874,
      "grad_norm": 0.002043746178969741,
      "learning_rate": 7.906122448979592e-06,
      "loss": 0.0001,
      "step": 1640
    },
    {
      "epoch": 2.2119738386718093,
      "grad_norm": 0.018899807706475258,
      "learning_rate": 7.89251700680272e-06,
      "loss": 0.0001,
      "step": 1650
    },
    {
      "epoch": 2.2253899044105316,
      "grad_norm": 0.002977389842271805,
      "learning_rate": 7.87891156462585e-06,
      "loss": 0.0001,
      "step": 1660
    },
    {
      "epoch": 2.2388059701492535,
      "grad_norm": 0.005848774220794439,
      "learning_rate": 7.86530612244898e-06,
      "loss": 0.0001,
      "step": 1670
    },
    {
      "epoch": 2.252222035887976,
      "grad_norm": 0.009616418741643429,
      "learning_rate": 7.851700680272109e-06,
      "loss": 0.0001,
      "step": 1680
    },
    {
      "epoch": 2.265638101626698,
      "grad_norm": 0.003281299490481615,
      "learning_rate": 7.838095238095239e-06,
      "loss": 0.0001,
      "step": 1690
    },
    {
      "epoch": 2.27905416736542,
      "grad_norm": 0.0013692128704860806,
      "learning_rate": 7.824489795918367e-06,
      "loss": 0.0001,
      "step": 1700
    },
    {
      "epoch": 2.292470233104142,
      "grad_norm": 0.008110132068395615,
      "learning_rate": 7.810884353741497e-06,
      "loss": 0.0001,
      "step": 1710
    },
    {
      "epoch": 2.3058862988428643,
      "grad_norm": 0.017125768586993217,
      "learning_rate": 7.797278911564626e-06,
      "loss": 0.0001,
      "step": 1720
    },
    {
      "epoch": 2.3193023645815867,
      "grad_norm": 0.008767153136432171,
      "learning_rate": 7.783673469387755e-06,
      "loss": 0.0001,
      "step": 1730
    },
    {
      "epoch": 2.3327184303203086,
      "grad_norm": 0.0089266924187541,
      "learning_rate": 7.770068027210885e-06,
      "loss": 0.0001,
      "step": 1740
    },
    {
      "epoch": 2.3461344960590305,
      "grad_norm": 0.002555306302383542,
      "learning_rate": 7.756462585034015e-06,
      "loss": 0.0001,
      "step": 1750
    },
    {
      "epoch": 2.359550561797753,
      "grad_norm": 0.0042754486203193665,
      "learning_rate": 7.742857142857144e-06,
      "loss": 0.0001,
      "step": 1760
    },
    {
      "epoch": 2.372966627536475,
      "grad_norm": 0.0029309745877981186,
      "learning_rate": 7.729251700680272e-06,
      "loss": 0.0001,
      "step": 1770
    },
    {
      "epoch": 2.386382693275197,
      "grad_norm": 0.014499344862997532,
      "learning_rate": 7.715646258503402e-06,
      "loss": 0.0001,
      "step": 1780
    },
    {
      "epoch": 2.399798759013919,
      "grad_norm": 0.00936861615628004,
      "learning_rate": 7.702040816326532e-06,
      "loss": 0.0001,
      "step": 1790
    },
    {
      "epoch": 2.4132148247526413,
      "grad_norm": 0.0011793774319812655,
      "learning_rate": 7.68843537414966e-06,
      "loss": 0.0001,
      "step": 1800
    },
    {
      "epoch": 2.4266308904913636,
      "grad_norm": 0.011903301812708378,
      "learning_rate": 7.674829931972789e-06,
      "loss": 0.0001,
      "step": 1810
    },
    {
      "epoch": 2.4400469562300855,
      "grad_norm": 0.002753976732492447,
      "learning_rate": 7.661224489795919e-06,
      "loss": 0.0001,
      "step": 1820
    },
    {
      "epoch": 2.453463021968808,
      "grad_norm": 0.0038106101565063,
      "learning_rate": 7.647619047619049e-06,
      "loss": 0.0001,
      "step": 1830
    },
    {
      "epoch": 2.4668790877075297,
      "grad_norm": 0.03616144880652428,
      "learning_rate": 7.634013605442177e-06,
      "loss": 0.0001,
      "step": 1840
    },
    {
      "epoch": 2.480295153446252,
      "grad_norm": 0.003658429952338338,
      "learning_rate": 7.620408163265307e-06,
      "loss": 0.0001,
      "step": 1850
    },
    {
      "epoch": 2.493711219184974,
      "grad_norm": 0.0022580449003726244,
      "learning_rate": 7.606802721088437e-06,
      "loss": 0.0001,
      "step": 1860
    },
    {
      "epoch": 2.507127284923696,
      "grad_norm": 0.002887255046516657,
      "learning_rate": 7.593197278911565e-06,
      "loss": 0.0001,
      "step": 1870
    },
    {
      "epoch": 2.520543350662418,
      "grad_norm": 0.004151143599301577,
      "learning_rate": 7.579591836734694e-06,
      "loss": 0.0001,
      "step": 1880
    },
    {
      "epoch": 2.5339594164011405,
      "grad_norm": 0.006727113854140043,
      "learning_rate": 7.565986394557824e-06,
      "loss": 0.0001,
      "step": 1890
    },
    {
      "epoch": 2.5473754821398624,
      "grad_norm": 0.002080373466014862,
      "learning_rate": 7.552380952380953e-06,
      "loss": 0.0001,
      "step": 1900
    },
    {
      "epoch": 2.5607915478785848,
      "grad_norm": 0.00247197481803596,
      "learning_rate": 7.5387755102040825e-06,
      "loss": 0.0001,
      "step": 1910
    },
    {
      "epoch": 2.5742076136173067,
      "grad_norm": 0.0013647614978253841,
      "learning_rate": 7.525170068027211e-06,
      "loss": 0.0001,
      "step": 1920
    },
    {
      "epoch": 2.587623679356029,
      "grad_norm": 0.003786007408052683,
      "learning_rate": 7.511564625850341e-06,
      "loss": 0.0001,
      "step": 1930
    },
    {
      "epoch": 2.601039745094751,
      "grad_norm": 0.006573874037712812,
      "learning_rate": 7.49795918367347e-06,
      "loss": 0.0001,
      "step": 1940
    },
    {
      "epoch": 2.6144558108334732,
      "grad_norm": 0.004228429403156042,
      "learning_rate": 7.4843537414966e-06,
      "loss": 0.0001,
      "step": 1950
    },
    {
      "epoch": 2.627871876572195,
      "grad_norm": 0.001415091217495501,
      "learning_rate": 7.470748299319729e-06,
      "loss": 0.0001,
      "step": 1960
    },
    {
      "epoch": 2.6412879423109175,
      "grad_norm": 0.002598811173811555,
      "learning_rate": 7.457142857142857e-06,
      "loss": 0.0001,
      "step": 1970
    },
    {
      "epoch": 2.6547040080496394,
      "grad_norm": 0.006415530573576689,
      "learning_rate": 7.443537414965986e-06,
      "loss": 0.0001,
      "step": 1980
    },
    {
      "epoch": 2.6681200737883617,
      "grad_norm": 0.001760294777341187,
      "learning_rate": 7.429931972789116e-06,
      "loss": 0.0001,
      "step": 1990
    },
    {
      "epoch": 2.6815361395270836,
      "grad_norm": 0.004206601530313492,
      "learning_rate": 7.4163265306122455e-06,
      "loss": 0.0001,
      "step": 2000
    },
    {
      "epoch": 2.694952205265806,
      "grad_norm": 0.002793689025565982,
      "learning_rate": 7.4027210884353755e-06,
      "loss": 0.0001,
      "step": 2010
    },
    {
      "epoch": 2.708368271004528,
      "grad_norm": 0.020041918382048607,
      "learning_rate": 7.389115646258505e-06,
      "loss": 0.0002,
      "step": 2020
    },
    {
      "epoch": 2.72178433674325,
      "grad_norm": 0.010157653130590916,
      "learning_rate": 7.375510204081633e-06,
      "loss": 0.0001,
      "step": 2030
    },
    {
      "epoch": 2.735200402481972,
      "grad_norm": 0.001991471741348505,
      "learning_rate": 7.361904761904762e-06,
      "loss": 0.0001,
      "step": 2040
    },
    {
      "epoch": 2.7486164682206944,
      "grad_norm": 0.0061231679283082485,
      "learning_rate": 7.348299319727892e-06,
      "loss": 0.0001,
      "step": 2050
    },
    {
      "epoch": 2.7620325339594163,
      "grad_norm": 0.0012230457505211234,
      "learning_rate": 7.334693877551021e-06,
      "loss": 0.0001,
      "step": 2060
    },
    {
      "epoch": 2.7754485996981386,
      "grad_norm": 0.0026001306250691414,
      "learning_rate": 7.32108843537415e-06,
      "loss": 0.0,
      "step": 2070
    },
    {
      "epoch": 2.7888646654368605,
      "grad_norm": 0.003336530178785324,
      "learning_rate": 7.3074829931972794e-06,
      "loss": 0.0001,
      "step": 2080
    },
    {
      "epoch": 2.802280731175583,
      "grad_norm": 0.0009481155429966748,
      "learning_rate": 7.2938775510204086e-06,
      "loss": 0.0001,
      "step": 2090
    },
    {
      "epoch": 2.8156967969143047,
      "grad_norm": 0.0016233677743002772,
      "learning_rate": 7.280272108843538e-06,
      "loss": 0.0001,
      "step": 2100
    },
    {
      "epoch": 2.829112862653027,
      "grad_norm": 0.002122779143974185,
      "learning_rate": 7.266666666666668e-06,
      "loss": 0.0001,
      "step": 2110
    },
    {
      "epoch": 2.842528928391749,
      "grad_norm": 0.06119764968752861,
      "learning_rate": 7.253061224489797e-06,
      "loss": 0.0002,
      "step": 2120
    },
    {
      "epoch": 2.8559449941304713,
      "grad_norm": 0.012154514901340008,
      "learning_rate": 7.239455782312925e-06,
      "loss": 0.0001,
      "step": 2130
    },
    {
      "epoch": 2.869361059869193,
      "grad_norm": 0.004435798618942499,
      "learning_rate": 7.225850340136055e-06,
      "loss": 0.0001,
      "step": 2140
    },
    {
      "epoch": 2.8827771256079155,
      "grad_norm": 0.012795004062354565,
      "learning_rate": 7.212244897959184e-06,
      "loss": 0.0001,
      "step": 2150
    },
    {
      "epoch": 2.8961931913466374,
      "grad_norm": 0.019770370796322823,
      "learning_rate": 7.198639455782313e-06,
      "loss": 0.0001,
      "step": 2160
    },
    {
      "epoch": 2.90960925708536,
      "grad_norm": 0.002614338416606188,
      "learning_rate": 7.185034013605443e-06,
      "loss": 0.0001,
      "step": 2170
    },
    {
      "epoch": 2.9230253228240817,
      "grad_norm": 0.0017871998716145754,
      "learning_rate": 7.1714285714285725e-06,
      "loss": 0.0001,
      "step": 2180
    },
    {
      "epoch": 2.936441388562804,
      "grad_norm": 0.00378431030549109,
      "learning_rate": 7.157823129251701e-06,
      "loss": 0.0,
      "step": 2190
    },
    {
      "epoch": 2.949857454301526,
      "grad_norm": 0.0028363976161926985,
      "learning_rate": 7.144217687074831e-06,
      "loss": 0.0001,
      "step": 2200
    },
    {
      "epoch": 2.9632735200402482,
      "grad_norm": 0.0011810186551883817,
      "learning_rate": 7.13061224489796e-06,
      "loss": 0.0001,
      "step": 2210
    },
    {
      "epoch": 2.9766895857789706,
      "grad_norm": 0.0022395981941372156,
      "learning_rate": 7.117006802721089e-06,
      "loss": 0.0,
      "step": 2220
    },
    {
      "epoch": 2.9901056515176925,
      "grad_norm": 0.013774311169981956,
      "learning_rate": 7.103401360544219e-06,
      "loss": 0.0001,
      "step": 2230
    },
    {
      "epoch": 3.0026832131477446,
      "grad_norm": 0.005116249900311232,
      "learning_rate": 7.089795918367347e-06,
      "loss": 0.0001,
      "step": 2240
    },
    {
      "epoch": 3.0160992788864665,
      "grad_norm": 0.0039436654187738895,
      "learning_rate": 7.076190476190476e-06,
      "loss": 0.0,
      "step": 2250
    },
    {
      "epoch": 3.029515344625189,
      "grad_norm": 0.010223492980003357,
      "learning_rate": 7.0625850340136055e-06,
      "loss": 0.0001,
      "step": 2260
    },
    {
      "epoch": 3.0429314103639107,
      "grad_norm": 0.006580539513379335,
      "learning_rate": 7.0489795918367355e-06,
      "loss": 0.0,
      "step": 2270
    },
    {
      "epoch": 3.056347476102633,
      "grad_norm": 0.0028978241607546806,
      "learning_rate": 7.035374149659865e-06,
      "loss": 0.0001,
      "step": 2280
    },
    {
      "epoch": 3.069763541841355,
      "grad_norm": 0.0019363637547940016,
      "learning_rate": 7.021768707482993e-06,
      "loss": 0.0001,
      "step": 2290
    },
    {
      "epoch": 3.0831796075800773,
      "grad_norm": 0.0029540671966969967,
      "learning_rate": 7.008163265306123e-06,
      "loss": 0.0001,
      "step": 2300
    },
    {
      "epoch": 3.096595673318799,
      "grad_norm": 0.003700015600770712,
      "learning_rate": 6.994557823129252e-06,
      "loss": 0.0001,
      "step": 2310
    },
    {
      "epoch": 3.1100117390575215,
      "grad_norm": 0.0059687416069209576,
      "learning_rate": 6.980952380952381e-06,
      "loss": 0.0001,
      "step": 2320
    },
    {
      "epoch": 3.1234278047962434,
      "grad_norm": 0.0014500602846965194,
      "learning_rate": 6.967346938775511e-06,
      "loss": 0.0,
      "step": 2330
    },
    {
      "epoch": 3.1368438705349657,
      "grad_norm": 0.00233418308198452,
      "learning_rate": 6.95374149659864e-06,
      "loss": 0.0,
      "step": 2340
    },
    {
      "epoch": 3.1502599362736876,
      "grad_norm": 0.0034093912690877914,
      "learning_rate": 6.940136054421769e-06,
      "loss": 0.0,
      "step": 2350
    },
    {
      "epoch": 3.16367600201241,
      "grad_norm": 0.0014493392081931233,
      "learning_rate": 6.9265306122448986e-06,
      "loss": 0.0001,
      "step": 2360
    },
    {
      "epoch": 3.177092067751132,
      "grad_norm": 0.0020341547206044197,
      "learning_rate": 6.912925170068028e-06,
      "loss": 0.0,
      "step": 2370
    },
    {
      "epoch": 3.190508133489854,
      "grad_norm": 0.006680504884570837,
      "learning_rate": 6.899319727891157e-06,
      "loss": 0.0001,
      "step": 2380
    },
    {
      "epoch": 3.203924199228576,
      "grad_norm": 0.0023772239219397306,
      "learning_rate": 6.885714285714287e-06,
      "loss": 0.0001,
      "step": 2390
    },
    {
      "epoch": 3.2173402649672984,
      "grad_norm": 0.0009977818699553609,
      "learning_rate": 6.872108843537415e-06,
      "loss": 0.0,
      "step": 2400
    },
    {
      "epoch": 3.2307563307060203,
      "grad_norm": 0.0026909129228442907,
      "learning_rate": 6.858503401360544e-06,
      "loss": 0.0,
      "step": 2410
    },
    {
      "epoch": 3.2441723964447426,
      "grad_norm": 0.002747792052105069,
      "learning_rate": 6.844897959183674e-06,
      "loss": 0.0001,
      "step": 2420
    },
    {
      "epoch": 3.2575884621834645,
      "grad_norm": 0.005881343502551317,
      "learning_rate": 6.831292517006803e-06,
      "loss": 0.0001,
      "step": 2430
    },
    {
      "epoch": 3.271004527922187,
      "grad_norm": 0.003217263612896204,
      "learning_rate": 6.8176870748299325e-06,
      "loss": 0.0,
      "step": 2440
    },
    {
      "epoch": 3.2844205936609088,
      "grad_norm": 0.005166760180145502,
      "learning_rate": 6.8040816326530625e-06,
      "loss": 0.0001,
      "step": 2450
    },
    {
      "epoch": 3.297836659399631,
      "grad_norm": 0.002036899793893099,
      "learning_rate": 6.790476190476191e-06,
      "loss": 0.0,
      "step": 2460
    },
    {
      "epoch": 3.311252725138353,
      "grad_norm": 0.0208852868527174,
      "learning_rate": 6.77687074829932e-06,
      "loss": 0.0001,
      "step": 2470
    },
    {
      "epoch": 3.3246687908770753,
      "grad_norm": 0.0018496583215892315,
      "learning_rate": 6.76326530612245e-06,
      "loss": 0.0,
      "step": 2480
    },
    {
      "epoch": 3.3380848566157972,
      "grad_norm": 0.005627647507935762,
      "learning_rate": 6.749659863945579e-06,
      "loss": 0.0,
      "step": 2490
    },
    {
      "epoch": 3.3515009223545196,
      "grad_norm": 0.0017430559964850545,
      "learning_rate": 6.736054421768708e-06,
      "loss": 0.0,
      "step": 2500
    },
    {
      "epoch": 3.3649169880932415,
      "grad_norm": 0.004414454568177462,
      "learning_rate": 6.7224489795918364e-06,
      "loss": 0.0001,
      "step": 2510
    },
    {
      "epoch": 3.378333053831964,
      "grad_norm": 0.0014384587993845344,
      "learning_rate": 6.708843537414966e-06,
      "loss": 0.0,
      "step": 2520
    },
    {
      "epoch": 3.3917491195706857,
      "grad_norm": 0.0013923401711508632,
      "learning_rate": 6.6952380952380956e-06,
      "loss": 0.0,
      "step": 2530
    },
    {
      "epoch": 3.405165185309408,
      "grad_norm": 0.0024336983915418386,
      "learning_rate": 6.6816326530612255e-06,
      "loss": 0.0001,
      "step": 2540
    },
    {
      "epoch": 3.4185812510481304,
      "grad_norm": 0.008209668099880219,
      "learning_rate": 6.668027210884355e-06,
      "loss": 0.0001,
      "step": 2550
    },
    {
      "epoch": 3.4319973167868523,
      "grad_norm": 0.04155799373984337,
      "learning_rate": 6.654421768707483e-06,
      "loss": 0.0,
      "step": 2560
    },
    {
      "epoch": 3.445413382525574,
      "grad_norm": 0.010676662437617779,
      "learning_rate": 6.640816326530612e-06,
      "loss": 0.0001,
      "step": 2570
    },
    {
      "epoch": 3.4588294482642965,
      "grad_norm": 0.0013484098017215729,
      "learning_rate": 6.627210884353742e-06,
      "loss": 0.0,
      "step": 2580
    },
    {
      "epoch": 3.472245514003019,
      "grad_norm": 0.005181198474019766,
      "learning_rate": 6.613605442176871e-06,
      "loss": 0.0,
      "step": 2590
    },
    {
      "epoch": 3.4856615797417407,
      "grad_norm": 0.0013853654963895679,
      "learning_rate": 6.600000000000001e-06,
      "loss": 0.0001,
      "step": 2600
    },
    {
      "epoch": 3.4990776454804626,
      "grad_norm": 0.009922298602759838,
      "learning_rate": 6.58639455782313e-06,
      "loss": 0.0,
      "step": 2610
    },
    {
      "epoch": 3.512493711219185,
      "grad_norm": 0.004350037779659033,
      "learning_rate": 6.572789115646259e-06,
      "loss": 0.0001,
      "step": 2620
    },
    {
      "epoch": 3.5259097769579073,
      "grad_norm": 0.00157169287558645,
      "learning_rate": 6.559183673469388e-06,
      "loss": 0.0001,
      "step": 2630
    },
    {
      "epoch": 3.539325842696629,
      "grad_norm": 0.0031274522189050913,
      "learning_rate": 6.545578231292518e-06,
      "loss": 0.0,
      "step": 2640
    },
    {
      "epoch": 3.552741908435351,
      "grad_norm": 0.0011902616824954748,
      "learning_rate": 6.531972789115647e-06,
      "loss": 0.0,
      "step": 2650
    },
    {
      "epoch": 3.5661579741740734,
      "grad_norm": 0.003321925876662135,
      "learning_rate": 6.518367346938777e-06,
      "loss": 0.0001,
      "step": 2660
    },
    {
      "epoch": 3.5795740399127958,
      "grad_norm": 0.0015439444687217474,
      "learning_rate": 6.504761904761905e-06,
      "loss": 0.0,
      "step": 2670
    },
    {
      "epoch": 3.5929901056515177,
      "grad_norm": 0.011512505821883678,
      "learning_rate": 6.491156462585034e-06,
      "loss": 0.0001,
      "step": 2680
    },
    {
      "epoch": 3.6064061713902396,
      "grad_norm": 0.001508119748905301,
      "learning_rate": 6.477551020408163e-06,
      "loss": 0.0001,
      "step": 2690
    },
    {
      "epoch": 3.619822237128962,
      "grad_norm": 0.004612276796251535,
      "learning_rate": 6.463945578231293e-06,
      "loss": 0.0001,
      "step": 2700
    },
    {
      "epoch": 3.6332383028676842,
      "grad_norm": 0.001688609248958528,
      "learning_rate": 6.4503401360544225e-06,
      "loss": 0.0001,
      "step": 2710
    },
    {
      "epoch": 3.646654368606406,
      "grad_norm": 0.00610068254172802,
      "learning_rate": 6.436734693877551e-06,
      "loss": 0.0,
      "step": 2720
    },
    {
      "epoch": 3.660070434345128,
      "grad_norm": 0.007173886056989431,
      "learning_rate": 6.423129251700681e-06,
      "loss": 0.0,
      "step": 2730
    },
    {
      "epoch": 3.6734865000838504,
      "grad_norm": 0.0036630025133490562,
      "learning_rate": 6.40952380952381e-06,
      "loss": 0.0,
      "step": 2740
    },
    {
      "epoch": 3.6869025658225727,
      "grad_norm": 0.0031528063118457794,
      "learning_rate": 6.395918367346939e-06,
      "loss": 0.0,
      "step": 2750
    },
    {
      "epoch": 3.7003186315612946,
      "grad_norm": 0.0024429126642644405,
      "learning_rate": 6.382312925170069e-06,
      "loss": 0.0001,
      "step": 2760
    },
    {
      "epoch": 3.713734697300017,
      "grad_norm": 0.0018457547994330525,
      "learning_rate": 6.368707482993198e-06,
      "loss": 0.0,
      "step": 2770
    },
    {
      "epoch": 3.727150763038739,
      "grad_norm": 0.002495759865269065,
      "learning_rate": 6.3551020408163264e-06,
      "loss": 0.0001,
      "step": 2780
    },
    {
      "epoch": 3.740566828777461,
      "grad_norm": 0.010052178986370564,
      "learning_rate": 6.3414965986394564e-06,
      "loss": 0.0,
      "step": 2790
    },
    {
      "epoch": 3.753982894516183,
      "grad_norm": 0.003098687855526805,
      "learning_rate": 6.3278911564625856e-06,
      "loss": 0.0,
      "step": 2800
    },
    {
      "epoch": 3.7673989602549054,
      "grad_norm": 0.0035737103316932917,
      "learning_rate": 6.314285714285715e-06,
      "loss": 0.0,
      "step": 2810
    },
    {
      "epoch": 3.7808150259936273,
      "grad_norm": 0.006344784051179886,
      "learning_rate": 6.300680272108845e-06,
      "loss": 0.0001,
      "step": 2820
    },
    {
      "epoch": 3.7942310917323496,
      "grad_norm": 0.002581303007900715,
      "learning_rate": 6.287074829931973e-06,
      "loss": 0.0,
      "step": 2830
    },
    {
      "epoch": 3.8076471574710715,
      "grad_norm": 0.0022377835121005774,
      "learning_rate": 6.273469387755102e-06,
      "loss": 0.0,
      "step": 2840
    },
    {
      "epoch": 3.821063223209794,
      "grad_norm": 0.007627592422068119,
      "learning_rate": 6.259863945578232e-06,
      "loss": 0.0,
      "step": 2850
    },
    {
      "epoch": 3.8344792889485158,
      "grad_norm": 0.004816337954252958,
      "learning_rate": 6.246258503401361e-06,
      "loss": 0.0001,
      "step": 2860
    },
    {
      "epoch": 3.847895354687238,
      "grad_norm": 0.0012975456193089485,
      "learning_rate": 6.23265306122449e-06,
      "loss": 0.0,
      "step": 2870
    },
    {
      "epoch": 3.86131142042596,
      "grad_norm": 0.0025792496744543314,
      "learning_rate": 6.21904761904762e-06,
      "loss": 0.0,
      "step": 2880
    },
    {
      "epoch": 3.8747274861646823,
      "grad_norm": 0.0016252961941063404,
      "learning_rate": 6.205442176870749e-06,
      "loss": 0.0,
      "step": 2890
    },
    {
      "epoch": 3.888143551903404,
      "grad_norm": 0.0017140214331448078,
      "learning_rate": 6.191836734693878e-06,
      "loss": 0.0,
      "step": 2900
    },
    {
      "epoch": 3.9015596176421266,
      "grad_norm": 0.0038332357071340084,
      "learning_rate": 6.178231292517008e-06,
      "loss": 0.0,
      "step": 2910
    },
    {
      "epoch": 3.9149756833808484,
      "grad_norm": 0.002445642836391926,
      "learning_rate": 6.164625850340137e-06,
      "loss": 0.0,
      "step": 2920
    },
    {
      "epoch": 3.928391749119571,
      "grad_norm": 0.002203642390668392,
      "learning_rate": 6.151020408163266e-06,
      "loss": 0.0,
      "step": 2930
    },
    {
      "epoch": 3.9418078148582927,
      "grad_norm": 0.0008768612751737237,
      "learning_rate": 6.137414965986394e-06,
      "loss": 0.0001,
      "step": 2940
    },
    {
      "epoch": 3.955223880597015,
      "grad_norm": 0.0034466704819351435,
      "learning_rate": 6.123809523809524e-06,
      "loss": 0.0,
      "step": 2950
    },
    {
      "epoch": 3.968639946335737,
      "grad_norm": 0.0016024599317461252,
      "learning_rate": 6.110204081632653e-06,
      "loss": 0.0,
      "step": 2960
    },
    {
      "epoch": 3.9820560120744593,
      "grad_norm": 0.005146961193531752,
      "learning_rate": 6.096598639455783e-06,
      "loss": 0.0,
      "step": 2970
    },
    {
      "epoch": 3.995472077813181,
      "grad_norm": 0.0008743353537283838,
      "learning_rate": 6.0829931972789125e-06,
      "loss": 0.0,
      "step": 2980
    },
    {
      "epoch": 4.008049639443233,
      "grad_norm": 0.004997056443244219,
      "learning_rate": 6.069387755102041e-06,
      "loss": 0.0,
      "step": 2990
    },
    {
      "epoch": 4.021465705181956,
      "grad_norm": 0.003666286589577794,
      "learning_rate": 6.05578231292517e-06,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 4.034881770920678,
      "grad_norm": 0.002816723193973303,
      "learning_rate": 6.0421768707483e-06,
      "loss": 0.0,
      "step": 3010
    },
    {
      "epoch": 4.048297836659399,
      "grad_norm": 0.0024939628783613443,
      "learning_rate": 6.028571428571429e-06,
      "loss": 0.0001,
      "step": 3020
    },
    {
      "epoch": 4.061713902398122,
      "grad_norm": 0.002829312812536955,
      "learning_rate": 6.014965986394559e-06,
      "loss": 0.0,
      "step": 3030
    },
    {
      "epoch": 4.075129968136844,
      "grad_norm": 0.002327574649825692,
      "learning_rate": 6.001360544217688e-06,
      "loss": 0.0,
      "step": 3040
    },
    {
      "epoch": 4.088546033875566,
      "grad_norm": 0.0015355508076027036,
      "learning_rate": 5.9877551020408165e-06,
      "loss": 0.0,
      "step": 3050
    },
    {
      "epoch": 4.101962099614288,
      "grad_norm": 0.003142026951536536,
      "learning_rate": 5.974149659863946e-06,
      "loss": 0.0,
      "step": 3060
    },
    {
      "epoch": 4.11537816535301,
      "grad_norm": 0.016826294362545013,
      "learning_rate": 5.9605442176870756e-06,
      "loss": 0.0,
      "step": 3070
    },
    {
      "epoch": 4.1287942310917325,
      "grad_norm": 0.0020732381381094456,
      "learning_rate": 5.946938775510205e-06,
      "loss": 0.0,
      "step": 3080
    },
    {
      "epoch": 4.142210296830455,
      "grad_norm": 0.001334581058472395,
      "learning_rate": 5.933333333333335e-06,
      "loss": 0.0,
      "step": 3090
    },
    {
      "epoch": 4.155626362569176,
      "grad_norm": 0.007496236823499203,
      "learning_rate": 5.919727891156463e-06,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 4.169042428307899,
      "grad_norm": 0.004159731790423393,
      "learning_rate": 5.906122448979592e-06,
      "loss": 0.0,
      "step": 3110
    },
    {
      "epoch": 4.182458494046621,
      "grad_norm": 0.0010666303569450974,
      "learning_rate": 5.892517006802721e-06,
      "loss": 0.0,
      "step": 3120
    },
    {
      "epoch": 4.195874559785343,
      "grad_norm": 0.0072515178471803665,
      "learning_rate": 5.878911564625851e-06,
      "loss": 0.0,
      "step": 3130
    },
    {
      "epoch": 4.209290625524065,
      "grad_norm": 0.0007486745016649365,
      "learning_rate": 5.86530612244898e-06,
      "loss": 0.0,
      "step": 3140
    },
    {
      "epoch": 4.222706691262787,
      "grad_norm": 0.0016980130458250642,
      "learning_rate": 5.851700680272109e-06,
      "loss": 0.0,
      "step": 3150
    },
    {
      "epoch": 4.236122757001509,
      "grad_norm": 0.004118628799915314,
      "learning_rate": 5.838095238095239e-06,
      "loss": 0.0,
      "step": 3160
    },
    {
      "epoch": 4.249538822740232,
      "grad_norm": 0.0013991502346470952,
      "learning_rate": 5.824489795918368e-06,
      "loss": 0.0,
      "step": 3170
    },
    {
      "epoch": 4.262954888478953,
      "grad_norm": 0.0025990279391407967,
      "learning_rate": 5.810884353741497e-06,
      "loss": 0.0,
      "step": 3180
    },
    {
      "epoch": 4.2763709542176755,
      "grad_norm": 0.0014306990196928382,
      "learning_rate": 5.797278911564627e-06,
      "loss": 0.0,
      "step": 3190
    },
    {
      "epoch": 4.289787019956398,
      "grad_norm": 0.0022143430542200804,
      "learning_rate": 5.783673469387756e-06,
      "loss": 0.0,
      "step": 3200
    },
    {
      "epoch": 4.30320308569512,
      "grad_norm": 0.0015076611889526248,
      "learning_rate": 5.770068027210884e-06,
      "loss": 0.0,
      "step": 3210
    },
    {
      "epoch": 4.316619151433842,
      "grad_norm": 0.0008206369820982218,
      "learning_rate": 5.756462585034014e-06,
      "loss": 0.0,
      "step": 3220
    },
    {
      "epoch": 4.330035217172564,
      "grad_norm": 0.0006794020882807672,
      "learning_rate": 5.742857142857143e-06,
      "loss": 0.0,
      "step": 3230
    },
    {
      "epoch": 4.343451282911286,
      "grad_norm": 0.0009746497380547225,
      "learning_rate": 5.7292517006802725e-06,
      "loss": 0.0,
      "step": 3240
    },
    {
      "epoch": 4.356867348650009,
      "grad_norm": 0.0008747500251047313,
      "learning_rate": 5.7156462585034025e-06,
      "loss": 0.0,
      "step": 3250
    },
    {
      "epoch": 4.37028341438873,
      "grad_norm": 0.002303330460563302,
      "learning_rate": 5.702040816326531e-06,
      "loss": 0.0001,
      "step": 3260
    },
    {
      "epoch": 4.3836994801274525,
      "grad_norm": 0.0014184261672198772,
      "learning_rate": 5.68843537414966e-06,
      "loss": 0.0,
      "step": 3270
    },
    {
      "epoch": 4.397115545866175,
      "grad_norm": 0.008181584067642689,
      "learning_rate": 5.67482993197279e-06,
      "loss": 0.0,
      "step": 3280
    },
    {
      "epoch": 4.410531611604897,
      "grad_norm": 0.0052769603207707405,
      "learning_rate": 5.661224489795919e-06,
      "loss": 0.0,
      "step": 3290
    },
    {
      "epoch": 4.423947677343619,
      "grad_norm": 0.004024076275527477,
      "learning_rate": 5.647619047619048e-06,
      "loss": 0.0001,
      "step": 3300
    },
    {
      "epoch": 4.437363743082341,
      "grad_norm": 0.0012126988731324673,
      "learning_rate": 5.6340136054421765e-06,
      "loss": 0.0,
      "step": 3310
    },
    {
      "epoch": 4.450779808821063,
      "grad_norm": 0.0018695816397666931,
      "learning_rate": 5.6204081632653065e-06,
      "loss": 0.0,
      "step": 3320
    },
    {
      "epoch": 4.464195874559786,
      "grad_norm": 0.0005778571357950568,
      "learning_rate": 5.606802721088436e-06,
      "loss": 0.0,
      "step": 3330
    },
    {
      "epoch": 4.477611940298507,
      "grad_norm": 0.0015941164456307888,
      "learning_rate": 5.593197278911566e-06,
      "loss": 0.0,
      "step": 3340
    },
    {
      "epoch": 4.491028006037229,
      "grad_norm": 0.0012949892552569509,
      "learning_rate": 5.579591836734695e-06,
      "loss": 0.0,
      "step": 3350
    },
    {
      "epoch": 4.504444071775952,
      "grad_norm": 0.0032333743292838335,
      "learning_rate": 5.565986394557824e-06,
      "loss": 0.0,
      "step": 3360
    },
    {
      "epoch": 4.517860137514674,
      "grad_norm": 0.007359398994594812,
      "learning_rate": 5.552380952380952e-06,
      "loss": 0.0,
      "step": 3370
    },
    {
      "epoch": 4.531276203253396,
      "grad_norm": 0.0014420953812077641,
      "learning_rate": 5.538775510204082e-06,
      "loss": 0.0,
      "step": 3380
    },
    {
      "epoch": 4.544692268992118,
      "grad_norm": 0.0016825883649289608,
      "learning_rate": 5.525170068027211e-06,
      "loss": 0.0,
      "step": 3390
    },
    {
      "epoch": 4.55810833473084,
      "grad_norm": 0.06982743740081787,
      "learning_rate": 5.51156462585034e-06,
      "loss": 0.0001,
      "step": 3400
    },
    {
      "epoch": 4.5715244004695625,
      "grad_norm": 0.0016738640842959285,
      "learning_rate": 5.49795918367347e-06,
      "loss": 0.0,
      "step": 3410
    },
    {
      "epoch": 4.584940466208284,
      "grad_norm": 0.00123875355347991,
      "learning_rate": 5.484353741496599e-06,
      "loss": 0.0,
      "step": 3420
    },
    {
      "epoch": 4.598356531947006,
      "grad_norm": 0.0016996499616652727,
      "learning_rate": 5.470748299319728e-06,
      "loss": 0.0,
      "step": 3430
    },
    {
      "epoch": 4.611772597685729,
      "grad_norm": 0.004689380992203951,
      "learning_rate": 5.457142857142858e-06,
      "loss": 0.0,
      "step": 3440
    },
    {
      "epoch": 4.625188663424451,
      "grad_norm": 0.0015526176430284977,
      "learning_rate": 5.443537414965987e-06,
      "loss": 0.0,
      "step": 3450
    },
    {
      "epoch": 4.638604729163173,
      "grad_norm": 0.0030057134572416544,
      "learning_rate": 5.429931972789116e-06,
      "loss": 0.0,
      "step": 3460
    },
    {
      "epoch": 4.652020794901895,
      "grad_norm": 0.002013611374422908,
      "learning_rate": 5.416326530612246e-06,
      "loss": 0.0,
      "step": 3470
    },
    {
      "epoch": 4.665436860640617,
      "grad_norm": 0.0037457847502082586,
      "learning_rate": 5.402721088435374e-06,
      "loss": 0.0,
      "step": 3480
    },
    {
      "epoch": 4.6788529263793395,
      "grad_norm": 0.007766368333250284,
      "learning_rate": 5.3891156462585034e-06,
      "loss": 0.0,
      "step": 3490
    },
    {
      "epoch": 4.692268992118061,
      "grad_norm": 0.001813641982153058,
      "learning_rate": 5.3755102040816334e-06,
      "loss": 0.0,
      "step": 3500
    },
    {
      "epoch": 4.705685057856783,
      "grad_norm": 0.0010423375060781837,
      "learning_rate": 5.3619047619047626e-06,
      "loss": 0.0,
      "step": 3510
    },
    {
      "epoch": 4.719101123595506,
      "grad_norm": 0.0029974542558193207,
      "learning_rate": 5.348299319727892e-06,
      "loss": 0.0,
      "step": 3520
    },
    {
      "epoch": 4.732517189334228,
      "grad_norm": 0.0015464173629879951,
      "learning_rate": 5.334693877551021e-06,
      "loss": 0.0,
      "step": 3530
    },
    {
      "epoch": 4.74593325507295,
      "grad_norm": 0.005041399970650673,
      "learning_rate": 5.32108843537415e-06,
      "loss": 0.0,
      "step": 3540
    },
    {
      "epoch": 4.759349320811672,
      "grad_norm": 0.0007191360928118229,
      "learning_rate": 5.307482993197279e-06,
      "loss": 0.0,
      "step": 3550
    },
    {
      "epoch": 4.772765386550394,
      "grad_norm": 0.0013544211396947503,
      "learning_rate": 5.293877551020409e-06,
      "loss": 0.0,
      "step": 3560
    },
    {
      "epoch": 4.786181452289116,
      "grad_norm": 0.004541255999356508,
      "learning_rate": 5.280272108843538e-06,
      "loss": 0.0,
      "step": 3570
    },
    {
      "epoch": 4.799597518027838,
      "grad_norm": 0.0033899429254233837,
      "learning_rate": 5.2666666666666665e-06,
      "loss": 0.0,
      "step": 3580
    },
    {
      "epoch": 4.81301358376656,
      "grad_norm": 0.0048223803751170635,
      "learning_rate": 5.253061224489796e-06,
      "loss": 0.0,
      "step": 3590
    },
    {
      "epoch": 4.8264296495052825,
      "grad_norm": 0.0011631392408162355,
      "learning_rate": 5.239455782312926e-06,
      "loss": 0.0,
      "step": 3600
    },
    {
      "epoch": 4.839845715244005,
      "grad_norm": 0.005968868266791105,
      "learning_rate": 5.225850340136055e-06,
      "loss": 0.0,
      "step": 3610
    },
    {
      "epoch": 4.853261780982727,
      "grad_norm": 0.0007490195566788316,
      "learning_rate": 5.212244897959185e-06,
      "loss": 0.0,
      "step": 3620
    },
    {
      "epoch": 4.866677846721449,
      "grad_norm": 0.004459635820239782,
      "learning_rate": 5.198639455782314e-06,
      "loss": 0.0,
      "step": 3630
    },
    {
      "epoch": 4.880093912460171,
      "grad_norm": 0.006225191056728363,
      "learning_rate": 5.185034013605442e-06,
      "loss": 0.0,
      "step": 3640
    },
    {
      "epoch": 4.893509978198893,
      "grad_norm": 0.001461564563214779,
      "learning_rate": 5.171428571428571e-06,
      "loss": 0.0,
      "step": 3650
    },
    {
      "epoch": 4.906926043937616,
      "grad_norm": 0.0006999922916293144,
      "learning_rate": 5.157823129251701e-06,
      "loss": 0.0005,
      "step": 3660
    },
    {
      "epoch": 4.920342109676337,
      "grad_norm": 0.0004812095139641315,
      "learning_rate": 5.14421768707483e-06,
      "loss": 0.0,
      "step": 3670
    },
    {
      "epoch": 4.9337581754150595,
      "grad_norm": 0.00460372818633914,
      "learning_rate": 5.13061224489796e-06,
      "loss": 0.0,
      "step": 3680
    },
    {
      "epoch": 4.947174241153782,
      "grad_norm": 0.006163306999951601,
      "learning_rate": 5.117006802721089e-06,
      "loss": 0.0,
      "step": 3690
    },
    {
      "epoch": 4.960590306892504,
      "grad_norm": 0.00190328573808074,
      "learning_rate": 5.103401360544218e-06,
      "loss": 0.0,
      "step": 3700
    },
    {
      "epoch": 4.974006372631226,
      "grad_norm": 0.0021867842879146338,
      "learning_rate": 5.089795918367347e-06,
      "loss": 0.0,
      "step": 3710
    },
    {
      "epoch": 4.987422438369948,
      "grad_norm": 0.003254306735470891,
      "learning_rate": 5.076190476190477e-06,
      "loss": 0.0,
      "step": 3720
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.002474111970514059,
      "learning_rate": 5.062585034013606e-06,
      "loss": 0.0,
      "step": 3730
    },
    {
      "epoch": 5.013416065738722,
      "grad_norm": 0.0006518508889712393,
      "learning_rate": 5.048979591836734e-06,
      "loss": 0.0,
      "step": 3740
    },
    {
      "epoch": 5.026832131477445,
      "grad_norm": 0.002059964695945382,
      "learning_rate": 5.035374149659864e-06,
      "loss": 0.0,
      "step": 3750
    },
    {
      "epoch": 5.040248197216166,
      "grad_norm": 0.0015698131173849106,
      "learning_rate": 5.0217687074829935e-06,
      "loss": 0.0,
      "step": 3760
    },
    {
      "epoch": 5.0536642629548885,
      "grad_norm": 0.002000597072765231,
      "learning_rate": 5.008163265306123e-06,
      "loss": 0.0,
      "step": 3770
    },
    {
      "epoch": 5.067080328693611,
      "grad_norm": 0.002356360899284482,
      "learning_rate": 4.994557823129252e-06,
      "loss": 0.0,
      "step": 3780
    },
    {
      "epoch": 5.080496394432333,
      "grad_norm": 0.0012708253925666213,
      "learning_rate": 4.980952380952382e-06,
      "loss": 0.0,
      "step": 3790
    },
    {
      "epoch": 5.093912460171055,
      "grad_norm": 0.002111362526193261,
      "learning_rate": 4.967346938775511e-06,
      "loss": 0.0,
      "step": 3800
    },
    {
      "epoch": 5.107328525909777,
      "grad_norm": 0.0023333809804171324,
      "learning_rate": 4.95374149659864e-06,
      "loss": 0.0,
      "step": 3810
    },
    {
      "epoch": 5.120744591648499,
      "grad_norm": 0.0009094006381928921,
      "learning_rate": 4.940136054421769e-06,
      "loss": 0.0,
      "step": 3820
    },
    {
      "epoch": 5.134160657387222,
      "grad_norm": 0.001034968183375895,
      "learning_rate": 4.926530612244898e-06,
      "loss": 0.0,
      "step": 3830
    },
    {
      "epoch": 5.147576723125943,
      "grad_norm": 0.0012840419076383114,
      "learning_rate": 4.912925170068027e-06,
      "loss": 0.0,
      "step": 3840
    },
    {
      "epoch": 5.160992788864665,
      "grad_norm": 0.0008185437764041126,
      "learning_rate": 4.899319727891157e-06,
      "loss": 0.0,
      "step": 3850
    },
    {
      "epoch": 5.174408854603388,
      "grad_norm": 0.0055513703264296055,
      "learning_rate": 4.885714285714286e-06,
      "loss": 0.0,
      "step": 3860
    },
    {
      "epoch": 5.18782492034211,
      "grad_norm": 0.0006976982112973928,
      "learning_rate": 4.872108843537416e-06,
      "loss": 0.0,
      "step": 3870
    },
    {
      "epoch": 5.2012409860808315,
      "grad_norm": 0.00335649773478508,
      "learning_rate": 4.858503401360545e-06,
      "loss": 0.0,
      "step": 3880
    },
    {
      "epoch": 5.214657051819554,
      "grad_norm": 0.0007805055356584489,
      "learning_rate": 4.844897959183674e-06,
      "loss": 0.0021,
      "step": 3890
    },
    {
      "epoch": 5.228073117558276,
      "grad_norm": 0.003145375521853566,
      "learning_rate": 4.831292517006803e-06,
      "loss": 0.0,
      "step": 3900
    },
    {
      "epoch": 5.2414891832969985,
      "grad_norm": 0.0026304873172193766,
      "learning_rate": 4.817687074829933e-06,
      "loss": 0.0001,
      "step": 3910
    },
    {
      "epoch": 5.25490524903572,
      "grad_norm": 0.0028589130379259586,
      "learning_rate": 4.804081632653061e-06,
      "loss": 0.0,
      "step": 3920
    },
    {
      "epoch": 5.268321314774442,
      "grad_norm": 0.0016787477070465684,
      "learning_rate": 4.790476190476191e-06,
      "loss": 0.0,
      "step": 3930
    },
    {
      "epoch": 5.281737380513165,
      "grad_norm": 0.0018689880380406976,
      "learning_rate": 4.7768707482993196e-06,
      "loss": 0.0,
      "step": 3940
    },
    {
      "epoch": 5.295153446251887,
      "grad_norm": 0.001127507770434022,
      "learning_rate": 4.7632653061224495e-06,
      "loss": 0.0,
      "step": 3950
    },
    {
      "epoch": 5.3085695119906084,
      "grad_norm": 0.0027623395435512066,
      "learning_rate": 4.749659863945579e-06,
      "loss": 0.0,
      "step": 3960
    },
    {
      "epoch": 5.321985577729331,
      "grad_norm": 0.0019628407899290323,
      "learning_rate": 4.736054421768708e-06,
      "loss": 0.0,
      "step": 3970
    },
    {
      "epoch": 5.335401643468053,
      "grad_norm": 0.0007374425767920911,
      "learning_rate": 4.722448979591837e-06,
      "loss": 0.0,
      "step": 3980
    },
    {
      "epoch": 5.3488177092067755,
      "grad_norm": 0.0009069037041626871,
      "learning_rate": 4.708843537414967e-06,
      "loss": 0.0,
      "step": 3990
    },
    {
      "epoch": 5.362233774945497,
      "grad_norm": 0.0011037626536563039,
      "learning_rate": 4.695238095238095e-06,
      "loss": 0.0,
      "step": 4000
    },
    {
      "epoch": 5.375649840684219,
      "grad_norm": 0.0028148156125098467,
      "learning_rate": 4.681632653061225e-06,
      "loss": 0.0,
      "step": 4010
    },
    {
      "epoch": 5.389065906422942,
      "grad_norm": 0.004090636037290096,
      "learning_rate": 4.668027210884354e-06,
      "loss": 0.0,
      "step": 4020
    },
    {
      "epoch": 5.402481972161664,
      "grad_norm": 0.020868593826889992,
      "learning_rate": 4.6544217687074835e-06,
      "loss": 0.0001,
      "step": 4030
    },
    {
      "epoch": 5.415898037900385,
      "grad_norm": 0.008643390610814095,
      "learning_rate": 4.640816326530613e-06,
      "loss": 0.0,
      "step": 4040
    },
    {
      "epoch": 5.429314103639108,
      "grad_norm": 0.00123026582878083,
      "learning_rate": 4.627210884353742e-06,
      "loss": 0.0,
      "step": 4050
    },
    {
      "epoch": 5.44273016937783,
      "grad_norm": 0.0014515738002955914,
      "learning_rate": 4.613605442176871e-06,
      "loss": 0.001,
      "step": 4060
    },
    {
      "epoch": 5.456146235116552,
      "grad_norm": 0.003063562558963895,
      "learning_rate": 4.600000000000001e-06,
      "loss": 0.0,
      "step": 4070
    },
    {
      "epoch": 5.469562300855274,
      "grad_norm": 0.0055167293176054955,
      "learning_rate": 4.586394557823129e-06,
      "loss": 0.0,
      "step": 4080
    },
    {
      "epoch": 5.482978366593996,
      "grad_norm": 0.005455356556922197,
      "learning_rate": 4.572789115646259e-06,
      "loss": 0.0,
      "step": 4090
    },
    {
      "epoch": 5.4963944323327185,
      "grad_norm": 0.0007466785027645528,
      "learning_rate": 4.559183673469388e-06,
      "loss": 0.0,
      "step": 4100
    },
    {
      "epoch": 5.509810498071441,
      "grad_norm": 0.0012997762532904744,
      "learning_rate": 4.545578231292517e-06,
      "loss": 0.0,
      "step": 4110
    },
    {
      "epoch": 5.523226563810162,
      "grad_norm": 0.0016560960793867707,
      "learning_rate": 4.5319727891156465e-06,
      "loss": 0.0,
      "step": 4120
    },
    {
      "epoch": 5.536642629548885,
      "grad_norm": 0.001173457014374435,
      "learning_rate": 4.518367346938776e-06,
      "loss": 0.0,
      "step": 4130
    },
    {
      "epoch": 5.550058695287607,
      "grad_norm": 0.0061857146210968494,
      "learning_rate": 4.504761904761905e-06,
      "loss": 0.0,
      "step": 4140
    },
    {
      "epoch": 5.563474761026329,
      "grad_norm": 0.0038418176118284464,
      "learning_rate": 4.491156462585035e-06,
      "loss": 0.0,
      "step": 4150
    },
    {
      "epoch": 5.576890826765051,
      "grad_norm": 0.0033720096107572317,
      "learning_rate": 4.477551020408163e-06,
      "loss": 0.0,
      "step": 4160
    },
    {
      "epoch": 5.590306892503773,
      "grad_norm": 0.0019505947129800916,
      "learning_rate": 4.463945578231293e-06,
      "loss": 0.0,
      "step": 4170
    },
    {
      "epoch": 5.6037229582424954,
      "grad_norm": 0.0009204312809742987,
      "learning_rate": 4.450340136054422e-06,
      "loss": 0.0,
      "step": 4180
    },
    {
      "epoch": 5.617139023981218,
      "grad_norm": 0.0013152481988072395,
      "learning_rate": 4.436734693877551e-06,
      "loss": 0.0,
      "step": 4190
    },
    {
      "epoch": 5.630555089719939,
      "grad_norm": 0.006692263297736645,
      "learning_rate": 4.4231292517006804e-06,
      "loss": 0.0,
      "step": 4200
    },
    {
      "epoch": 5.643971155458662,
      "grad_norm": 0.000944292638450861,
      "learning_rate": 4.4095238095238096e-06,
      "loss": 0.0,
      "step": 4210
    },
    {
      "epoch": 5.657387221197384,
      "grad_norm": 0.0008776177419349551,
      "learning_rate": 4.395918367346939e-06,
      "loss": 0.0,
      "step": 4220
    },
    {
      "epoch": 5.670803286936106,
      "grad_norm": 0.001912103733047843,
      "learning_rate": 4.382312925170069e-06,
      "loss": 0.0,
      "step": 4230
    },
    {
      "epoch": 5.684219352674829,
      "grad_norm": 0.0008293589344248176,
      "learning_rate": 4.368707482993198e-06,
      "loss": 0.0,
      "step": 4240
    },
    {
      "epoch": 5.69763541841355,
      "grad_norm": 0.0011951670749112964,
      "learning_rate": 4.355102040816327e-06,
      "loss": 0.0,
      "step": 4250
    },
    {
      "epoch": 5.711051484152272,
      "grad_norm": 0.0013650304172188044,
      "learning_rate": 4.341496598639456e-06,
      "loss": 0.012,
      "step": 4260
    },
    {
      "epoch": 5.724467549890995,
      "grad_norm": 0.0010688467882573605,
      "learning_rate": 4.327891156462585e-06,
      "loss": 0.0,
      "step": 4270
    },
    {
      "epoch": 5.737883615629716,
      "grad_norm": 0.0010076510952785611,
      "learning_rate": 4.314285714285714e-06,
      "loss": 0.0,
      "step": 4280
    },
    {
      "epoch": 5.7512996813684385,
      "grad_norm": 0.002325182082131505,
      "learning_rate": 4.3006802721088435e-06,
      "loss": 0.0,
      "step": 4290
    },
    {
      "epoch": 5.764715747107161,
      "grad_norm": 0.0016065941890701652,
      "learning_rate": 4.2870748299319735e-06,
      "loss": 0.0,
      "step": 4300
    },
    {
      "epoch": 5.778131812845883,
      "grad_norm": 0.0011276521254330873,
      "learning_rate": 4.273469387755103e-06,
      "loss": 0.0,
      "step": 4310
    },
    {
      "epoch": 5.7915478785846055,
      "grad_norm": 0.002408968284726143,
      "learning_rate": 4.259863945578232e-06,
      "loss": 0.0,
      "step": 4320
    },
    {
      "epoch": 5.804963944323327,
      "grad_norm": 0.0018380052642896771,
      "learning_rate": 4.246258503401361e-06,
      "loss": 0.0,
      "step": 4330
    },
    {
      "epoch": 5.818380010062049,
      "grad_norm": 0.0011865287087857723,
      "learning_rate": 4.23265306122449e-06,
      "loss": 0.0,
      "step": 4340
    },
    {
      "epoch": 5.831796075800772,
      "grad_norm": 0.0010591773316264153,
      "learning_rate": 4.219047619047619e-06,
      "loss": 0.0,
      "step": 4350
    },
    {
      "epoch": 5.845212141539493,
      "grad_norm": 0.0011873898329213262,
      "learning_rate": 4.205442176870749e-06,
      "loss": 0.0,
      "step": 4360
    },
    {
      "epoch": 5.858628207278215,
      "grad_norm": 0.0019753079395741224,
      "learning_rate": 4.191836734693877e-06,
      "loss": 0.0,
      "step": 4370
    },
    {
      "epoch": 5.872044273016938,
      "grad_norm": 0.0023506968282163143,
      "learning_rate": 4.178231292517007e-06,
      "loss": 0.0,
      "step": 4380
    },
    {
      "epoch": 5.88546033875566,
      "grad_norm": 0.001986113144084811,
      "learning_rate": 4.1646258503401365e-06,
      "loss": 0.0,
      "step": 4390
    },
    {
      "epoch": 5.898876404494382,
      "grad_norm": 0.0005681600305251777,
      "learning_rate": 4.151020408163266e-06,
      "loss": 0.0,
      "step": 4400
    },
    {
      "epoch": 5.912292470233104,
      "grad_norm": 0.0027745452243834734,
      "learning_rate": 4.137414965986395e-06,
      "loss": 0.0,
      "step": 4410
    },
    {
      "epoch": 5.925708535971826,
      "grad_norm": 0.0010708527406677604,
      "learning_rate": 4.123809523809525e-06,
      "loss": 0.0,
      "step": 4420
    },
    {
      "epoch": 5.939124601710549,
      "grad_norm": 0.0009244209504686296,
      "learning_rate": 4.110204081632653e-06,
      "loss": 0.0,
      "step": 4430
    },
    {
      "epoch": 5.95254066744927,
      "grad_norm": 0.019670194014906883,
      "learning_rate": 4.096598639455783e-06,
      "loss": 0.0,
      "step": 4440
    },
    {
      "epoch": 5.965956733187992,
      "grad_norm": 0.0009739695233292878,
      "learning_rate": 4.082993197278911e-06,
      "loss": 0.0,
      "step": 4450
    },
    {
      "epoch": 5.979372798926715,
      "grad_norm": 0.0010187742300331593,
      "learning_rate": 4.069387755102041e-06,
      "loss": 0.0,
      "step": 4460
    },
    {
      "epoch": 5.992788864665437,
      "grad_norm": 0.002512815874069929,
      "learning_rate": 4.0557823129251705e-06,
      "loss": 0.0,
      "step": 4470
    },
    {
      "epoch": 6.005366426295489,
      "grad_norm": 0.001956075197085738,
      "learning_rate": 4.0421768707483e-06,
      "loss": 0.0,
      "step": 4480
    },
    {
      "epoch": 6.018782492034211,
      "grad_norm": 0.015167980454862118,
      "learning_rate": 4.028571428571429e-06,
      "loss": 0.0,
      "step": 4490
    },
    {
      "epoch": 6.032198557772933,
      "grad_norm": 0.001931162434630096,
      "learning_rate": 4.014965986394559e-06,
      "loss": 0.0,
      "step": 4500
    },
    {
      "epoch": 6.045614623511655,
      "grad_norm": 0.00899286288768053,
      "learning_rate": 4.001360544217687e-06,
      "loss": 0.0,
      "step": 4510
    },
    {
      "epoch": 6.059030689250378,
      "grad_norm": 0.0013034922303631902,
      "learning_rate": 3.987755102040817e-06,
      "loss": 0.0,
      "step": 4520
    },
    {
      "epoch": 6.072446754989099,
      "grad_norm": 0.002614350989460945,
      "learning_rate": 3.974149659863945e-06,
      "loss": 0.0,
      "step": 4530
    },
    {
      "epoch": 6.085862820727821,
      "grad_norm": 0.0007206206792034209,
      "learning_rate": 3.960544217687075e-06,
      "loss": 0.0,
      "step": 4540
    },
    {
      "epoch": 6.099278886466544,
      "grad_norm": 0.01305035687983036,
      "learning_rate": 3.946938775510204e-06,
      "loss": 0.0,
      "step": 4550
    },
    {
      "epoch": 6.112694952205266,
      "grad_norm": 0.002923636930063367,
      "learning_rate": 3.9333333333333335e-06,
      "loss": 0.0,
      "step": 4560
    },
    {
      "epoch": 6.1261110179439875,
      "grad_norm": 0.0019511847058311105,
      "learning_rate": 3.919727891156463e-06,
      "loss": 0.0,
      "step": 4570
    },
    {
      "epoch": 6.13952708368271,
      "grad_norm": 0.0012158849276602268,
      "learning_rate": 3.906122448979593e-06,
      "loss": 0.0,
      "step": 4580
    },
    {
      "epoch": 6.152943149421432,
      "grad_norm": 0.001037880894728005,
      "learning_rate": 3.892517006802721e-06,
      "loss": 0.0,
      "step": 4590
    },
    {
      "epoch": 6.1663592151601545,
      "grad_norm": 0.000931343121919781,
      "learning_rate": 3.878911564625851e-06,
      "loss": 0.0,
      "step": 4600
    },
    {
      "epoch": 6.179775280898877,
      "grad_norm": 0.000541555171366781,
      "learning_rate": 3.86530612244898e-06,
      "loss": 0.0,
      "step": 4610
    },
    {
      "epoch": 6.193191346637598,
      "grad_norm": 0.0014331473503261805,
      "learning_rate": 3.851700680272109e-06,
      "loss": 0.0,
      "step": 4620
    },
    {
      "epoch": 6.206607412376321,
      "grad_norm": 0.0013025370426476002,
      "learning_rate": 3.838095238095238e-06,
      "loss": 0.0,
      "step": 4630
    },
    {
      "epoch": 6.220023478115043,
      "grad_norm": 0.0015266570262610912,
      "learning_rate": 3.8244897959183674e-06,
      "loss": 0.0,
      "step": 4640
    },
    {
      "epoch": 6.233439543853765,
      "grad_norm": 0.0007235915400087833,
      "learning_rate": 3.810884353741497e-06,
      "loss": 0.0,
      "step": 4650
    },
    {
      "epoch": 6.246855609592487,
      "grad_norm": 0.0011743229115381837,
      "learning_rate": 3.7972789115646265e-06,
      "loss": 0.0,
      "step": 4660
    },
    {
      "epoch": 6.260271675331209,
      "grad_norm": 0.0005805797991342843,
      "learning_rate": 3.7836734693877553e-06,
      "loss": 0.0,
      "step": 4670
    },
    {
      "epoch": 6.273687741069931,
      "grad_norm": 0.0009281931561417878,
      "learning_rate": 3.770068027210885e-06,
      "loss": 0.0,
      "step": 4680
    },
    {
      "epoch": 6.287103806808654,
      "grad_norm": 0.0014303827192634344,
      "learning_rate": 3.7564625850340144e-06,
      "loss": 0.0,
      "step": 4690
    },
    {
      "epoch": 6.300519872547375,
      "grad_norm": 0.0013520189095288515,
      "learning_rate": 3.742857142857143e-06,
      "loss": 0.0,
      "step": 4700
    },
    {
      "epoch": 6.313935938286098,
      "grad_norm": 0.002045491011813283,
      "learning_rate": 3.7292517006802726e-06,
      "loss": 0.0,
      "step": 4710
    },
    {
      "epoch": 6.32735200402482,
      "grad_norm": 0.0013234354555606842,
      "learning_rate": 3.7156462585034013e-06,
      "loss": 0.0,
      "step": 4720
    },
    {
      "epoch": 6.340768069763542,
      "grad_norm": 0.0023187692277133465,
      "learning_rate": 3.702040816326531e-06,
      "loss": 0.0,
      "step": 4730
    },
    {
      "epoch": 6.354184135502264,
      "grad_norm": 0.0011777649633586407,
      "learning_rate": 3.6884353741496605e-06,
      "loss": 0.0,
      "step": 4740
    },
    {
      "epoch": 6.367600201240986,
      "grad_norm": 0.0018911919323727489,
      "learning_rate": 3.674829931972789e-06,
      "loss": 0.0,
      "step": 4750
    },
    {
      "epoch": 6.381016266979708,
      "grad_norm": 0.001920832903124392,
      "learning_rate": 3.6612244897959187e-06,
      "loss": 0.0,
      "step": 4760
    },
    {
      "epoch": 6.394432332718431,
      "grad_norm": 0.001149544958025217,
      "learning_rate": 3.6476190476190483e-06,
      "loss": 0.0,
      "step": 4770
    },
    {
      "epoch": 6.407848398457152,
      "grad_norm": 0.0005330494605004787,
      "learning_rate": 3.634013605442177e-06,
      "loss": 0.0,
      "step": 4780
    },
    {
      "epoch": 6.4212644641958745,
      "grad_norm": 0.0008952511707320809,
      "learning_rate": 3.6204081632653066e-06,
      "loss": 0.0,
      "step": 4790
    },
    {
      "epoch": 6.434680529934597,
      "grad_norm": 0.008056018501520157,
      "learning_rate": 3.6068027210884353e-06,
      "loss": 0.0,
      "step": 4800
    },
    {
      "epoch": 6.448096595673319,
      "grad_norm": 0.0017443614779040217,
      "learning_rate": 3.593197278911565e-06,
      "loss": 0.0,
      "step": 4810
    },
    {
      "epoch": 6.461512661412041,
      "grad_norm": 0.002913332311436534,
      "learning_rate": 3.5795918367346944e-06,
      "loss": 0.0,
      "step": 4820
    },
    {
      "epoch": 6.474928727150763,
      "grad_norm": 0.0006531616090796888,
      "learning_rate": 3.565986394557823e-06,
      "loss": 0.0,
      "step": 4830
    },
    {
      "epoch": 6.488344792889485,
      "grad_norm": 0.0012272936291992664,
      "learning_rate": 3.5523809523809527e-06,
      "loss": 0.0,
      "step": 4840
    },
    {
      "epoch": 6.501760858628208,
      "grad_norm": 0.0014693266712129116,
      "learning_rate": 3.538775510204082e-06,
      "loss": 0.0,
      "step": 4850
    },
    {
      "epoch": 6.515176924366929,
      "grad_norm": 0.0010490001877769828,
      "learning_rate": 3.525170068027211e-06,
      "loss": 0.0,
      "step": 4860
    },
    {
      "epoch": 6.528592990105651,
      "grad_norm": 0.00438958453014493,
      "learning_rate": 3.5115646258503405e-06,
      "loss": 0.0,
      "step": 4870
    },
    {
      "epoch": 6.542009055844374,
      "grad_norm": 0.0030811268370598555,
      "learning_rate": 3.4979591836734696e-06,
      "loss": 0.0,
      "step": 4880
    },
    {
      "epoch": 6.555425121583096,
      "grad_norm": 0.0020033549517393112,
      "learning_rate": 3.4843537414965987e-06,
      "loss": 0.0,
      "step": 4890
    },
    {
      "epoch": 6.5688411873218175,
      "grad_norm": 0.0054788789711892605,
      "learning_rate": 3.4707482993197283e-06,
      "loss": 0.0,
      "step": 4900
    },
    {
      "epoch": 6.58225725306054,
      "grad_norm": 0.0011693347478285432,
      "learning_rate": 3.4571428571428574e-06,
      "loss": 0.0,
      "step": 4910
    },
    {
      "epoch": 6.595673318799262,
      "grad_norm": 0.0010451626731082797,
      "learning_rate": 3.4435374149659866e-06,
      "loss": 0.0,
      "step": 4920
    },
    {
      "epoch": 6.609089384537985,
      "grad_norm": 0.000723090604878962,
      "learning_rate": 3.429931972789116e-06,
      "loss": 0.0,
      "step": 4930
    },
    {
      "epoch": 6.622505450276706,
      "grad_norm": 0.0008617838611826301,
      "learning_rate": 3.4163265306122453e-06,
      "loss": 0.0,
      "step": 4940
    },
    {
      "epoch": 6.635921516015428,
      "grad_norm": 0.004658869002014399,
      "learning_rate": 3.4027210884353744e-06,
      "loss": 0.0,
      "step": 4950
    },
    {
      "epoch": 6.649337581754151,
      "grad_norm": 0.0009951965184882283,
      "learning_rate": 3.3891156462585035e-06,
      "loss": 0.0,
      "step": 4960
    },
    {
      "epoch": 6.662753647492873,
      "grad_norm": 0.0023362168576568365,
      "learning_rate": 3.3755102040816327e-06,
      "loss": 0.0,
      "step": 4970
    },
    {
      "epoch": 6.6761697132315945,
      "grad_norm": 0.0024481555446982384,
      "learning_rate": 3.3619047619047622e-06,
      "loss": 0.0,
      "step": 4980
    },
    {
      "epoch": 6.689585778970317,
      "grad_norm": 0.00060105393640697,
      "learning_rate": 3.3482993197278914e-06,
      "loss": 0.0,
      "step": 4990
    },
    {
      "epoch": 6.703001844709039,
      "grad_norm": 0.0013577734353020787,
      "learning_rate": 3.3346938775510205e-06,
      "loss": 0.0,
      "step": 5000
    },
    {
      "epoch": 6.7164179104477615,
      "grad_norm": 0.005171948578208685,
      "learning_rate": 3.32108843537415e-06,
      "loss": 0.0,
      "step": 5010
    },
    {
      "epoch": 6.729833976186483,
      "grad_norm": 0.0007161791436374187,
      "learning_rate": 3.307482993197279e-06,
      "loss": 0.0,
      "step": 5020
    },
    {
      "epoch": 6.743250041925205,
      "grad_norm": 0.0009186165989376605,
      "learning_rate": 3.2938775510204083e-06,
      "loss": 0.0,
      "step": 5030
    },
    {
      "epoch": 6.756666107663928,
      "grad_norm": 0.0017404790269210935,
      "learning_rate": 3.2802721088435375e-06,
      "loss": 0.0,
      "step": 5040
    },
    {
      "epoch": 6.77008217340265,
      "grad_norm": 0.0018610787810757756,
      "learning_rate": 3.266666666666667e-06,
      "loss": 0.0,
      "step": 5050
    },
    {
      "epoch": 6.783498239141371,
      "grad_norm": 0.0007058628252707422,
      "learning_rate": 3.253061224489796e-06,
      "loss": 0.0,
      "step": 5060
    },
    {
      "epoch": 6.796914304880094,
      "grad_norm": 0.0007769314688630402,
      "learning_rate": 3.2394557823129253e-06,
      "loss": 0.0,
      "step": 5070
    },
    {
      "epoch": 6.810330370618816,
      "grad_norm": 0.0015609891852363944,
      "learning_rate": 3.225850340136055e-06,
      "loss": 0.0,
      "step": 5080
    },
    {
      "epoch": 6.823746436357538,
      "grad_norm": 0.001399279572069645,
      "learning_rate": 3.212244897959184e-06,
      "loss": 0.0,
      "step": 5090
    },
    {
      "epoch": 6.837162502096261,
      "grad_norm": 0.0010374662233516574,
      "learning_rate": 3.198639455782313e-06,
      "loss": 0.0,
      "step": 5100
    },
    {
      "epoch": 6.850578567834982,
      "grad_norm": 0.0050595542415976524,
      "learning_rate": 3.1850340136054427e-06,
      "loss": 0.0,
      "step": 5110
    },
    {
      "epoch": 6.8639946335737045,
      "grad_norm": 0.0005702957278117537,
      "learning_rate": 3.1714285714285714e-06,
      "loss": 0.0,
      "step": 5120
    },
    {
      "epoch": 6.877410699312427,
      "grad_norm": 0.0007060884381644428,
      "learning_rate": 3.157823129251701e-06,
      "loss": 0.0,
      "step": 5130
    },
    {
      "epoch": 6.890826765051148,
      "grad_norm": 0.0023081533145159483,
      "learning_rate": 3.1442176870748305e-06,
      "loss": 0.0,
      "step": 5140
    },
    {
      "epoch": 6.904242830789871,
      "grad_norm": 0.00100639124866575,
      "learning_rate": 3.130612244897959e-06,
      "loss": 0.0001,
      "step": 5150
    },
    {
      "epoch": 6.917658896528593,
      "grad_norm": 0.0021428337786346674,
      "learning_rate": 3.1170068027210888e-06,
      "loss": 0.0,
      "step": 5160
    },
    {
      "epoch": 6.931074962267315,
      "grad_norm": 0.0006422081496566534,
      "learning_rate": 3.1034013605442183e-06,
      "loss": 0.0,
      "step": 5170
    },
    {
      "epoch": 6.944491028006038,
      "grad_norm": 0.0008194050169549882,
      "learning_rate": 3.089795918367347e-06,
      "loss": 0.0,
      "step": 5180
    },
    {
      "epoch": 6.957907093744759,
      "grad_norm": 0.0019567091949284077,
      "learning_rate": 3.0761904761904766e-06,
      "loss": 0.0,
      "step": 5190
    },
    {
      "epoch": 6.9713231594834815,
      "grad_norm": 0.0013294804375618696,
      "learning_rate": 3.062585034013606e-06,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 6.984739225222204,
      "grad_norm": 0.001378500135615468,
      "learning_rate": 3.048979591836735e-06,
      "loss": 0.0,
      "step": 5210
    },
    {
      "epoch": 6.998155290960925,
      "grad_norm": 0.0031370341312140226,
      "learning_rate": 3.0353741496598644e-06,
      "loss": 0.0,
      "step": 5220
    },
    {
      "epoch": 7.010732852590977,
      "grad_norm": 0.0010995508637279272,
      "learning_rate": 3.021768707482993e-06,
      "loss": 0.0,
      "step": 5230
    },
    {
      "epoch": 7.0241489183297,
      "grad_norm": 0.0018444417510181665,
      "learning_rate": 3.0081632653061227e-06,
      "loss": 0.0,
      "step": 5240
    },
    {
      "epoch": 7.037564984068422,
      "grad_norm": 0.0004231680650264025,
      "learning_rate": 2.9945578231292522e-06,
      "loss": 0.0,
      "step": 5250
    },
    {
      "epoch": 7.050981049807144,
      "grad_norm": 0.0013952333247289062,
      "learning_rate": 2.980952380952381e-06,
      "loss": 0.0,
      "step": 5260
    },
    {
      "epoch": 7.064397115545866,
      "grad_norm": 0.0029609224293380976,
      "learning_rate": 2.9673469387755105e-06,
      "loss": 0.0,
      "step": 5270
    },
    {
      "epoch": 7.077813181284588,
      "grad_norm": 0.0015567175578325987,
      "learning_rate": 2.95374149659864e-06,
      "loss": 0.0,
      "step": 5280
    },
    {
      "epoch": 7.0912292470233105,
      "grad_norm": 0.0027830752078443766,
      "learning_rate": 2.9401360544217688e-06,
      "loss": 0.0,
      "step": 5290
    },
    {
      "epoch": 7.104645312762033,
      "grad_norm": 0.0021033219527453184,
      "learning_rate": 2.9265306122448983e-06,
      "loss": 0.0,
      "step": 5300
    },
    {
      "epoch": 7.118061378500754,
      "grad_norm": 0.0006854005041532218,
      "learning_rate": 2.912925170068027e-06,
      "loss": 0.0,
      "step": 5310
    },
    {
      "epoch": 7.131477444239477,
      "grad_norm": 0.0008769889245741069,
      "learning_rate": 2.8993197278911566e-06,
      "loss": 0.0,
      "step": 5320
    },
    {
      "epoch": 7.144893509978199,
      "grad_norm": 0.002479500137269497,
      "learning_rate": 2.885714285714286e-06,
      "loss": 0.0,
      "step": 5330
    },
    {
      "epoch": 7.158309575716921,
      "grad_norm": 0.00042652952834032476,
      "learning_rate": 2.872108843537415e-06,
      "loss": 0.0,
      "step": 5340
    },
    {
      "epoch": 7.171725641455643,
      "grad_norm": 0.001398713793605566,
      "learning_rate": 2.8585034013605444e-06,
      "loss": 0.0,
      "step": 5350
    },
    {
      "epoch": 7.185141707194365,
      "grad_norm": 0.0011481628753244877,
      "learning_rate": 2.844897959183674e-06,
      "loss": 0.0,
      "step": 5360
    },
    {
      "epoch": 7.198557772933087,
      "grad_norm": 0.0029012851882725954,
      "learning_rate": 2.8312925170068027e-06,
      "loss": 0.0,
      "step": 5370
    },
    {
      "epoch": 7.21197383867181,
      "grad_norm": 0.0007202368578873575,
      "learning_rate": 2.8176870748299323e-06,
      "loss": 0.0,
      "step": 5380
    },
    {
      "epoch": 7.225389904410531,
      "grad_norm": 0.0015156877925619483,
      "learning_rate": 2.8040816326530614e-06,
      "loss": 0.0001,
      "step": 5390
    },
    {
      "epoch": 7.2388059701492535,
      "grad_norm": 0.0012381704291328788,
      "learning_rate": 2.7904761904761905e-06,
      "loss": 0.0,
      "step": 5400
    },
    {
      "epoch": 7.252222035887976,
      "grad_norm": 0.0014814002206549048,
      "learning_rate": 2.77687074829932e-06,
      "loss": 0.0,
      "step": 5410
    },
    {
      "epoch": 7.265638101626698,
      "grad_norm": 0.0015552786644548178,
      "learning_rate": 2.7632653061224492e-06,
      "loss": 0.0,
      "step": 5420
    },
    {
      "epoch": 7.27905416736542,
      "grad_norm": 0.0019786320626735687,
      "learning_rate": 2.7496598639455783e-06,
      "loss": 0.0,
      "step": 5430
    },
    {
      "epoch": 7.292470233104142,
      "grad_norm": 0.0007175177452154458,
      "learning_rate": 2.736054421768708e-06,
      "loss": 0.0,
      "step": 5440
    },
    {
      "epoch": 7.305886298842864,
      "grad_norm": 0.0007602646946907043,
      "learning_rate": 2.722448979591837e-06,
      "loss": 0.0,
      "step": 5450
    },
    {
      "epoch": 7.319302364581587,
      "grad_norm": 0.0012935190461575985,
      "learning_rate": 2.708843537414966e-06,
      "loss": 0.0,
      "step": 5460
    },
    {
      "epoch": 7.332718430320309,
      "grad_norm": 0.0008597876876592636,
      "learning_rate": 2.6952380952380953e-06,
      "loss": 0.0,
      "step": 5470
    },
    {
      "epoch": 7.3461344960590305,
      "grad_norm": 0.00043067295337095857,
      "learning_rate": 2.681632653061225e-06,
      "loss": 0.0,
      "step": 5480
    },
    {
      "epoch": 7.359550561797753,
      "grad_norm": 0.0011290181428194046,
      "learning_rate": 2.668027210884354e-06,
      "loss": 0.0,
      "step": 5490
    },
    {
      "epoch": 7.372966627536475,
      "grad_norm": 0.00022301675926428288,
      "learning_rate": 2.654421768707483e-06,
      "loss": 0.0,
      "step": 5500
    },
    {
      "epoch": 7.386382693275197,
      "grad_norm": 0.0007404373027384281,
      "learning_rate": 2.6408163265306127e-06,
      "loss": 0.0,
      "step": 5510
    },
    {
      "epoch": 7.399798759013919,
      "grad_norm": 0.0006506499485112727,
      "learning_rate": 2.627210884353742e-06,
      "loss": 0.0,
      "step": 5520
    },
    {
      "epoch": 7.413214824752641,
      "grad_norm": 0.000534109422005713,
      "learning_rate": 2.613605442176871e-06,
      "loss": 0.0,
      "step": 5530
    },
    {
      "epoch": 7.426630890491364,
      "grad_norm": 0.0029002351220697165,
      "learning_rate": 2.6e-06,
      "loss": 0.0,
      "step": 5540
    },
    {
      "epoch": 7.440046956230086,
      "grad_norm": 0.00138796865940094,
      "learning_rate": 2.5863945578231292e-06,
      "loss": 0.0,
      "step": 5550
    },
    {
      "epoch": 7.453463021968807,
      "grad_norm": 0.0007017257157713175,
      "learning_rate": 2.5727891156462588e-06,
      "loss": 0.0,
      "step": 5560
    },
    {
      "epoch": 7.46687908770753,
      "grad_norm": 0.0017043881816789508,
      "learning_rate": 2.559183673469388e-06,
      "loss": 0.0,
      "step": 5570
    },
    {
      "epoch": 7.480295153446252,
      "grad_norm": 0.0011456598294898868,
      "learning_rate": 2.545578231292517e-06,
      "loss": 0.0,
      "step": 5580
    },
    {
      "epoch": 7.493711219184974,
      "grad_norm": 0.0014714532298967242,
      "learning_rate": 2.5319727891156466e-06,
      "loss": 0.0,
      "step": 5590
    },
    {
      "epoch": 7.507127284923696,
      "grad_norm": 0.0006572547135874629,
      "learning_rate": 2.5183673469387757e-06,
      "loss": 0.0,
      "step": 5600
    },
    {
      "epoch": 7.520543350662418,
      "grad_norm": 0.0017737827729433775,
      "learning_rate": 2.504761904761905e-06,
      "loss": 0.0,
      "step": 5610
    },
    {
      "epoch": 7.5339594164011405,
      "grad_norm": 0.0009989653481170535,
      "learning_rate": 2.4911564625850344e-06,
      "loss": 0.0,
      "step": 5620
    },
    {
      "epoch": 7.547375482139863,
      "grad_norm": 0.0010191041510552168,
      "learning_rate": 2.4775510204081636e-06,
      "loss": 0.0,
      "step": 5630
    },
    {
      "epoch": 7.560791547878584,
      "grad_norm": 0.0006963339983485639,
      "learning_rate": 2.4639455782312927e-06,
      "loss": 0.0,
      "step": 5640
    },
    {
      "epoch": 7.574207613617307,
      "grad_norm": 0.0007346669444814324,
      "learning_rate": 2.450340136054422e-06,
      "loss": 0.0,
      "step": 5650
    },
    {
      "epoch": 7.587623679356029,
      "grad_norm": 0.001087125507183373,
      "learning_rate": 2.4367346938775514e-06,
      "loss": 0.0,
      "step": 5660
    },
    {
      "epoch": 7.601039745094751,
      "grad_norm": 0.0005666548968292773,
      "learning_rate": 2.4231292517006805e-06,
      "loss": 0.0,
      "step": 5670
    },
    {
      "epoch": 7.614455810833473,
      "grad_norm": 0.00026453210739418864,
      "learning_rate": 2.4095238095238097e-06,
      "loss": 0.0,
      "step": 5680
    },
    {
      "epoch": 7.627871876572195,
      "grad_norm": 0.0003845978935714811,
      "learning_rate": 2.395918367346939e-06,
      "loss": 0.0,
      "step": 5690
    },
    {
      "epoch": 7.6412879423109175,
      "grad_norm": 0.0021026453468948603,
      "learning_rate": 2.3823129251700684e-06,
      "loss": 0.0,
      "step": 5700
    },
    {
      "epoch": 7.65470400804964,
      "grad_norm": 0.0005815104232169688,
      "learning_rate": 2.3687074829931975e-06,
      "loss": 0.0,
      "step": 5710
    },
    {
      "epoch": 7.668120073788361,
      "grad_norm": 0.00101080525200814,
      "learning_rate": 2.3551020408163266e-06,
      "loss": 0.0,
      "step": 5720
    },
    {
      "epoch": 7.681536139527084,
      "grad_norm": 0.0010792759712785482,
      "learning_rate": 2.341496598639456e-06,
      "loss": 0.0,
      "step": 5730
    },
    {
      "epoch": 7.694952205265806,
      "grad_norm": 0.003941030241549015,
      "learning_rate": 2.3278911564625853e-06,
      "loss": 0.0,
      "step": 5740
    },
    {
      "epoch": 7.708368271004528,
      "grad_norm": 0.0007413593702949584,
      "learning_rate": 2.3142857142857145e-06,
      "loss": 0.0,
      "step": 5750
    },
    {
      "epoch": 7.72178433674325,
      "grad_norm": 0.00200077542103827,
      "learning_rate": 2.3006802721088436e-06,
      "loss": 0.0,
      "step": 5760
    },
    {
      "epoch": 7.735200402481972,
      "grad_norm": 0.002374598290771246,
      "learning_rate": 2.287074829931973e-06,
      "loss": 0.0,
      "step": 5770
    },
    {
      "epoch": 7.748616468220694,
      "grad_norm": 0.0023378850892186165,
      "learning_rate": 2.2734693877551023e-06,
      "loss": 0.0,
      "step": 5780
    },
    {
      "epoch": 7.762032533959417,
      "grad_norm": 0.002407374558970332,
      "learning_rate": 2.2598639455782314e-06,
      "loss": 0.0,
      "step": 5790
    },
    {
      "epoch": 7.775448599698138,
      "grad_norm": 0.0018573213601484895,
      "learning_rate": 2.2462585034013605e-06,
      "loss": 0.0,
      "step": 5800
    },
    {
      "epoch": 7.7888646654368605,
      "grad_norm": 0.0007600143435411155,
      "learning_rate": 2.23265306122449e-06,
      "loss": 0.0,
      "step": 5810
    },
    {
      "epoch": 7.802280731175583,
      "grad_norm": 0.002183896256610751,
      "learning_rate": 2.2190476190476192e-06,
      "loss": 0.0,
      "step": 5820
    },
    {
      "epoch": 7.815696796914305,
      "grad_norm": 0.0011078390525653958,
      "learning_rate": 2.2054421768707484e-06,
      "loss": 0.0,
      "step": 5830
    },
    {
      "epoch": 7.829112862653027,
      "grad_norm": 0.0005510732880793512,
      "learning_rate": 2.1918367346938775e-06,
      "loss": 0.0,
      "step": 5840
    },
    {
      "epoch": 7.842528928391749,
      "grad_norm": 0.0019245065050199628,
      "learning_rate": 2.178231292517007e-06,
      "loss": 0.0,
      "step": 5850
    },
    {
      "epoch": 7.855944994130471,
      "grad_norm": 0.0006845608004368842,
      "learning_rate": 2.164625850340136e-06,
      "loss": 0.0,
      "step": 5860
    },
    {
      "epoch": 7.869361059869194,
      "grad_norm": 0.0015675014583393931,
      "learning_rate": 2.1510204081632653e-06,
      "loss": 0.0,
      "step": 5870
    },
    {
      "epoch": 7.882777125607915,
      "grad_norm": 0.0007497489568777382,
      "learning_rate": 2.1374149659863945e-06,
      "loss": 0.0,
      "step": 5880
    },
    {
      "epoch": 7.896193191346637,
      "grad_norm": 0.0007203234126791358,
      "learning_rate": 2.123809523809524e-06,
      "loss": 0.0,
      "step": 5890
    },
    {
      "epoch": 7.90960925708536,
      "grad_norm": 0.0003825428429991007,
      "learning_rate": 2.110204081632653e-06,
      "loss": 0.0,
      "step": 5900
    },
    {
      "epoch": 7.923025322824082,
      "grad_norm": 0.0014905226416885853,
      "learning_rate": 2.0965986394557823e-06,
      "loss": 0.0,
      "step": 5910
    },
    {
      "epoch": 7.936441388562804,
      "grad_norm": 0.0008677905425429344,
      "learning_rate": 2.0829931972789114e-06,
      "loss": 0.0,
      "step": 5920
    },
    {
      "epoch": 7.949857454301526,
      "grad_norm": 0.003176476340740919,
      "learning_rate": 2.069387755102041e-06,
      "loss": 0.0,
      "step": 5930
    },
    {
      "epoch": 7.963273520040248,
      "grad_norm": 0.001276036142371595,
      "learning_rate": 2.05578231292517e-06,
      "loss": 0.0,
      "step": 5940
    },
    {
      "epoch": 7.976689585778971,
      "grad_norm": 0.0014655288541689515,
      "learning_rate": 2.0421768707482993e-06,
      "loss": 0.0,
      "step": 5950
    },
    {
      "epoch": 7.990105651517693,
      "grad_norm": 0.001577045302838087,
      "learning_rate": 2.028571428571429e-06,
      "loss": 0.0,
      "step": 5960
    },
    {
      "epoch": 8.002683213147744,
      "grad_norm": 0.0004016409511677921,
      "learning_rate": 2.014965986394558e-06,
      "loss": 0.0,
      "step": 5970
    },
    {
      "epoch": 8.016099278886466,
      "grad_norm": 0.0007212716736830771,
      "learning_rate": 2.001360544217687e-06,
      "loss": 0.0,
      "step": 5980
    },
    {
      "epoch": 8.029515344625189,
      "grad_norm": 0.0005257152952253819,
      "learning_rate": 1.9877551020408166e-06,
      "loss": 0.0,
      "step": 5990
    },
    {
      "epoch": 8.042931410363911,
      "grad_norm": 0.0008050952455960214,
      "learning_rate": 1.9741496598639458e-06,
      "loss": 0.0,
      "step": 6000
    },
    {
      "epoch": 8.056347476102633,
      "grad_norm": 0.0027327327989041805,
      "learning_rate": 1.960544217687075e-06,
      "loss": 0.0,
      "step": 6010
    },
    {
      "epoch": 8.069763541841356,
      "grad_norm": 0.0006136762676760554,
      "learning_rate": 1.9469387755102045e-06,
      "loss": 0.0,
      "step": 6020
    },
    {
      "epoch": 8.083179607580076,
      "grad_norm": 0.0014744570944458246,
      "learning_rate": 1.9333333333333336e-06,
      "loss": 0.0,
      "step": 6030
    },
    {
      "epoch": 8.096595673318799,
      "grad_norm": 0.00034980184864252806,
      "learning_rate": 1.9197278911564627e-06,
      "loss": 0.0,
      "step": 6040
    },
    {
      "epoch": 8.110011739057521,
      "grad_norm": 0.0009542870684526861,
      "learning_rate": 1.906122448979592e-06,
      "loss": 0.0,
      "step": 6050
    },
    {
      "epoch": 8.123427804796243,
      "grad_norm": 0.00039030835614539683,
      "learning_rate": 1.8925170068027212e-06,
      "loss": 0.0,
      "step": 6060
    },
    {
      "epoch": 8.136843870534966,
      "grad_norm": 0.001080428482964635,
      "learning_rate": 1.8789115646258503e-06,
      "loss": 0.0,
      "step": 6070
    },
    {
      "epoch": 8.150259936273688,
      "grad_norm": 0.00044564352720044553,
      "learning_rate": 1.8653061224489797e-06,
      "loss": 0.0,
      "step": 6080
    },
    {
      "epoch": 8.16367600201241,
      "grad_norm": 0.0006211148574948311,
      "learning_rate": 1.851700680272109e-06,
      "loss": 0.0,
      "step": 6090
    },
    {
      "epoch": 8.177092067751133,
      "grad_norm": 0.0008752776775509119,
      "learning_rate": 1.8380952380952382e-06,
      "loss": 0.0,
      "step": 6100
    },
    {
      "epoch": 8.190508133489853,
      "grad_norm": 0.0005922599812038243,
      "learning_rate": 1.8244897959183675e-06,
      "loss": 0.0,
      "step": 6110
    },
    {
      "epoch": 8.203924199228576,
      "grad_norm": 0.0006968910456635058,
      "learning_rate": 1.8108843537414967e-06,
      "loss": 0.0,
      "step": 6120
    },
    {
      "epoch": 8.217340264967298,
      "grad_norm": 0.0012208754196763039,
      "learning_rate": 1.797278911564626e-06,
      "loss": 0.0,
      "step": 6130
    },
    {
      "epoch": 8.23075633070602,
      "grad_norm": 0.0008883046102710068,
      "learning_rate": 1.7836734693877553e-06,
      "loss": 0.0,
      "step": 6140
    },
    {
      "epoch": 8.244172396444743,
      "grad_norm": 0.0031004101037979126,
      "learning_rate": 1.7700680272108845e-06,
      "loss": 0.0,
      "step": 6150
    },
    {
      "epoch": 8.257588462183465,
      "grad_norm": 0.02012326940894127,
      "learning_rate": 1.7564625850340136e-06,
      "loss": 0.0,
      "step": 6160
    },
    {
      "epoch": 8.271004527922187,
      "grad_norm": 0.0013608953449875116,
      "learning_rate": 1.7428571428571432e-06,
      "loss": 0.0,
      "step": 6170
    },
    {
      "epoch": 8.28442059366091,
      "grad_norm": 0.0003389042685739696,
      "learning_rate": 1.7292517006802723e-06,
      "loss": 0.0,
      "step": 6180
    },
    {
      "epoch": 8.29783665939963,
      "grad_norm": 0.0006210734136402607,
      "learning_rate": 1.7156462585034014e-06,
      "loss": 0.0,
      "step": 6190
    },
    {
      "epoch": 8.311252725138353,
      "grad_norm": 0.0006137446034699678,
      "learning_rate": 1.7020408163265306e-06,
      "loss": 0.0,
      "step": 6200
    },
    {
      "epoch": 8.324668790877075,
      "grad_norm": 0.0009952865075320005,
      "learning_rate": 1.6884353741496601e-06,
      "loss": 0.0,
      "step": 6210
    },
    {
      "epoch": 8.338084856615797,
      "grad_norm": 0.00045732708531431854,
      "learning_rate": 1.6748299319727893e-06,
      "loss": 0.0,
      "step": 6220
    },
    {
      "epoch": 8.35150092235452,
      "grad_norm": 0.0010672151111066341,
      "learning_rate": 1.6612244897959184e-06,
      "loss": 0.0,
      "step": 6230
    },
    {
      "epoch": 8.364916988093242,
      "grad_norm": 0.0010138048091903329,
      "learning_rate": 1.6476190476190475e-06,
      "loss": 0.0,
      "step": 6240
    },
    {
      "epoch": 8.378333053831964,
      "grad_norm": 0.000810727768111974,
      "learning_rate": 1.634013605442177e-06,
      "loss": 0.0,
      "step": 6250
    },
    {
      "epoch": 8.391749119570687,
      "grad_norm": 0.0007907443214207888,
      "learning_rate": 1.6204081632653062e-06,
      "loss": 0.0,
      "step": 6260
    },
    {
      "epoch": 8.405165185309407,
      "grad_norm": 0.0005927020101808012,
      "learning_rate": 1.6068027210884354e-06,
      "loss": 0.0,
      "step": 6270
    },
    {
      "epoch": 8.41858125104813,
      "grad_norm": 0.0011124390875920653,
      "learning_rate": 1.593197278911565e-06,
      "loss": 0.0,
      "step": 6280
    },
    {
      "epoch": 8.431997316786852,
      "grad_norm": 0.0008819613140076399,
      "learning_rate": 1.579591836734694e-06,
      "loss": 0.0,
      "step": 6290
    },
    {
      "epoch": 8.445413382525574,
      "grad_norm": 0.0006979755125939846,
      "learning_rate": 1.5659863945578232e-06,
      "loss": 0.0,
      "step": 6300
    },
    {
      "epoch": 8.458829448264297,
      "grad_norm": 0.0008141290163621306,
      "learning_rate": 1.5523809523809525e-06,
      "loss": 0.0,
      "step": 6310
    },
    {
      "epoch": 8.472245514003019,
      "grad_norm": 0.0008895471110008657,
      "learning_rate": 1.5387755102040819e-06,
      "loss": 0.0,
      "step": 6320
    },
    {
      "epoch": 8.485661579741741,
      "grad_norm": 0.0010767201893031597,
      "learning_rate": 1.525170068027211e-06,
      "loss": 0.0,
      "step": 6330
    },
    {
      "epoch": 8.499077645480464,
      "grad_norm": 0.0010983386309817433,
      "learning_rate": 1.5115646258503401e-06,
      "loss": 0.0,
      "step": 6340
    },
    {
      "epoch": 8.512493711219186,
      "grad_norm": 0.00025972037110477686,
      "learning_rate": 1.4979591836734695e-06,
      "loss": 0.0,
      "step": 6350
    },
    {
      "epoch": 8.525909776957906,
      "grad_norm": 0.0007606882136315107,
      "learning_rate": 1.4843537414965988e-06,
      "loss": 0.0,
      "step": 6360
    },
    {
      "epoch": 8.539325842696629,
      "grad_norm": 0.0006586434901691973,
      "learning_rate": 1.470748299319728e-06,
      "loss": 0.0,
      "step": 6370
    },
    {
      "epoch": 8.552741908435351,
      "grad_norm": 0.0009832503274083138,
      "learning_rate": 1.4571428571428573e-06,
      "loss": 0.0,
      "step": 6380
    },
    {
      "epoch": 8.566157974174073,
      "grad_norm": 0.0005779959610663354,
      "learning_rate": 1.4435374149659865e-06,
      "loss": 0.0,
      "step": 6390
    },
    {
      "epoch": 8.579574039912796,
      "grad_norm": 0.0005371160223148763,
      "learning_rate": 1.4299319727891158e-06,
      "loss": 0.0,
      "step": 6400
    },
    {
      "epoch": 8.592990105651518,
      "grad_norm": 0.000517061329446733,
      "learning_rate": 1.4163265306122451e-06,
      "loss": 0.0,
      "step": 6410
    },
    {
      "epoch": 8.60640617139024,
      "grad_norm": 0.0019925355445593596,
      "learning_rate": 1.4027210884353743e-06,
      "loss": 0.0,
      "step": 6420
    },
    {
      "epoch": 8.619822237128961,
      "grad_norm": 0.001942948205396533,
      "learning_rate": 1.3891156462585034e-06,
      "loss": 0.0,
      "step": 6430
    },
    {
      "epoch": 8.633238302867683,
      "grad_norm": 0.0012861706782132387,
      "learning_rate": 1.375510204081633e-06,
      "loss": 0.0,
      "step": 6440
    },
    {
      "epoch": 8.646654368606406,
      "grad_norm": 0.0003196544712409377,
      "learning_rate": 1.361904761904762e-06,
      "loss": 0.0,
      "step": 6450
    },
    {
      "epoch": 8.660070434345128,
      "grad_norm": 0.0008941130945459008,
      "learning_rate": 1.3482993197278912e-06,
      "loss": 0.0,
      "step": 6460
    },
    {
      "epoch": 8.67348650008385,
      "grad_norm": 0.0009888747008517385,
      "learning_rate": 1.3346938775510204e-06,
      "loss": 0.0,
      "step": 6470
    },
    {
      "epoch": 8.686902565822573,
      "grad_norm": 0.0006286150892265141,
      "learning_rate": 1.32108843537415e-06,
      "loss": 0.0,
      "step": 6480
    },
    {
      "epoch": 8.700318631561295,
      "grad_norm": 0.007267175707966089,
      "learning_rate": 1.307482993197279e-06,
      "loss": 0.0,
      "step": 6490
    },
    {
      "epoch": 8.713734697300017,
      "grad_norm": 0.0005771477590315044,
      "learning_rate": 1.2938775510204082e-06,
      "loss": 0.0,
      "step": 6500
    },
    {
      "epoch": 8.72715076303874,
      "grad_norm": 0.00056738022249192,
      "learning_rate": 1.2802721088435373e-06,
      "loss": 0.0,
      "step": 6510
    },
    {
      "epoch": 8.74056682877746,
      "grad_norm": 0.0012885832693427801,
      "learning_rate": 1.2666666666666669e-06,
      "loss": 0.0,
      "step": 6520
    },
    {
      "epoch": 8.753982894516183,
      "grad_norm": 0.00019660404359456152,
      "learning_rate": 1.253061224489796e-06,
      "loss": 0.0,
      "step": 6530
    },
    {
      "epoch": 8.767398960254905,
      "grad_norm": 0.0007175183854997158,
      "learning_rate": 1.2394557823129252e-06,
      "loss": 0.0,
      "step": 6540
    },
    {
      "epoch": 8.780815025993627,
      "grad_norm": 0.0021861374843865633,
      "learning_rate": 1.2258503401360545e-06,
      "loss": 0.0,
      "step": 6550
    },
    {
      "epoch": 8.79423109173235,
      "grad_norm": 0.0009411455830559134,
      "learning_rate": 1.2122448979591836e-06,
      "loss": 0.0,
      "step": 6560
    },
    {
      "epoch": 8.807647157471072,
      "grad_norm": 0.0008901043329387903,
      "learning_rate": 1.198639455782313e-06,
      "loss": 0.0,
      "step": 6570
    },
    {
      "epoch": 8.821063223209794,
      "grad_norm": 0.0006483881152234972,
      "learning_rate": 1.1850340136054423e-06,
      "loss": 0.0,
      "step": 6580
    },
    {
      "epoch": 8.834479288948517,
      "grad_norm": 0.0008545442251488566,
      "learning_rate": 1.1714285714285715e-06,
      "loss": 0.0,
      "step": 6590
    },
    {
      "epoch": 8.847895354687237,
      "grad_norm": 0.0015346655854955316,
      "learning_rate": 1.1578231292517008e-06,
      "loss": 0.0,
      "step": 6600
    },
    {
      "epoch": 8.86131142042596,
      "grad_norm": 0.00047518612700514495,
      "learning_rate": 1.1442176870748302e-06,
      "loss": 0.0,
      "step": 6610
    },
    {
      "epoch": 8.874727486164682,
      "grad_norm": 0.0006261748494580388,
      "learning_rate": 1.1306122448979593e-06,
      "loss": 0.0,
      "step": 6620
    },
    {
      "epoch": 8.888143551903404,
      "grad_norm": 0.000636629294604063,
      "learning_rate": 1.1170068027210886e-06,
      "loss": 0.0,
      "step": 6630
    },
    {
      "epoch": 8.901559617642127,
      "grad_norm": 0.0005393115570768714,
      "learning_rate": 1.1034013605442178e-06,
      "loss": 0.0,
      "step": 6640
    },
    {
      "epoch": 8.914975683380849,
      "grad_norm": 0.000464043696410954,
      "learning_rate": 1.0897959183673471e-06,
      "loss": 0.0,
      "step": 6650
    },
    {
      "epoch": 8.928391749119571,
      "grad_norm": 0.0015880020800977945,
      "learning_rate": 1.0761904761904763e-06,
      "loss": 0.0,
      "step": 6660
    },
    {
      "epoch": 8.941807814858294,
      "grad_norm": 0.004957802128046751,
      "learning_rate": 1.0625850340136056e-06,
      "loss": 0.0,
      "step": 6670
    },
    {
      "epoch": 8.955223880597014,
      "grad_norm": 0.0008180925506167114,
      "learning_rate": 1.0489795918367347e-06,
      "loss": 0.0,
      "step": 6680
    },
    {
      "epoch": 8.968639946335736,
      "grad_norm": 0.0008905475260689855,
      "learning_rate": 1.035374149659864e-06,
      "loss": 0.0,
      "step": 6690
    },
    {
      "epoch": 8.982056012074459,
      "grad_norm": 0.000816842308267951,
      "learning_rate": 1.0217687074829932e-06,
      "loss": 0.0,
      "step": 6700
    },
    {
      "epoch": 8.995472077813181,
      "grad_norm": 0.0013833820121362805,
      "learning_rate": 1.0081632653061226e-06,
      "loss": 0.0,
      "step": 6710
    },
    {
      "epoch": 9.008049639443234,
      "grad_norm": 0.0012909371871501207,
      "learning_rate": 9.945578231292517e-07,
      "loss": 0.0,
      "step": 6720
    },
    {
      "epoch": 9.021465705181955,
      "grad_norm": 0.0012653269805014133,
      "learning_rate": 9.80952380952381e-07,
      "loss": 0.0,
      "step": 6730
    },
    {
      "epoch": 9.034881770920677,
      "grad_norm": 0.0006189124542288482,
      "learning_rate": 9.673469387755102e-07,
      "loss": 0.0,
      "step": 6740
    },
    {
      "epoch": 9.0482978366594,
      "grad_norm": 0.00039487704634666443,
      "learning_rate": 9.537414965986395e-07,
      "loss": 0.0,
      "step": 6750
    },
    {
      "epoch": 9.061713902398122,
      "grad_norm": 0.00109280610922724,
      "learning_rate": 9.401360544217688e-07,
      "loss": 0.0,
      "step": 6760
    },
    {
      "epoch": 9.075129968136844,
      "grad_norm": 0.0006768414750695229,
      "learning_rate": 9.26530612244898e-07,
      "loss": 0.0,
      "step": 6770
    },
    {
      "epoch": 9.088546033875566,
      "grad_norm": 0.0007894349400885403,
      "learning_rate": 9.129251700680272e-07,
      "loss": 0.0,
      "step": 6780
    },
    {
      "epoch": 9.101962099614289,
      "grad_norm": 0.0012480799341574311,
      "learning_rate": 8.993197278911566e-07,
      "loss": 0.0,
      "step": 6790
    },
    {
      "epoch": 9.115378165353011,
      "grad_norm": 0.000454668392194435,
      "learning_rate": 8.857142857142857e-07,
      "loss": 0.0,
      "step": 6800
    },
    {
      "epoch": 9.128794231091732,
      "grad_norm": 0.004062335472553968,
      "learning_rate": 8.721088435374151e-07,
      "loss": 0.0,
      "step": 6810
    },
    {
      "epoch": 9.142210296830454,
      "grad_norm": 0.0004481373180169612,
      "learning_rate": 8.585034013605442e-07,
      "loss": 0.0,
      "step": 6820
    },
    {
      "epoch": 9.155626362569176,
      "grad_norm": 0.0012584930518642068,
      "learning_rate": 8.448979591836735e-07,
      "loss": 0.0,
      "step": 6830
    },
    {
      "epoch": 9.169042428307899,
      "grad_norm": 0.0006721466779708862,
      "learning_rate": 8.312925170068029e-07,
      "loss": 0.0,
      "step": 6840
    },
    {
      "epoch": 9.182458494046621,
      "grad_norm": 0.001006723497994244,
      "learning_rate": 8.17687074829932e-07,
      "loss": 0.0,
      "step": 6850
    },
    {
      "epoch": 9.195874559785343,
      "grad_norm": 0.0029841589275747538,
      "learning_rate": 8.040816326530614e-07,
      "loss": 0.0,
      "step": 6860
    },
    {
      "epoch": 9.209290625524066,
      "grad_norm": 0.0005967403412796557,
      "learning_rate": 7.904761904761905e-07,
      "loss": 0.0,
      "step": 6870
    },
    {
      "epoch": 9.222706691262788,
      "grad_norm": 0.00040384457679465413,
      "learning_rate": 7.768707482993199e-07,
      "loss": 0.0,
      "step": 6880
    },
    {
      "epoch": 9.236122757001509,
      "grad_norm": 0.0015172363491728902,
      "learning_rate": 7.63265306122449e-07,
      "loss": 0.0,
      "step": 6890
    },
    {
      "epoch": 9.24953882274023,
      "grad_norm": 0.0031300876289606094,
      "learning_rate": 7.496598639455783e-07,
      "loss": 0.0,
      "step": 6900
    },
    {
      "epoch": 9.262954888478953,
      "grad_norm": 0.0014573151711374521,
      "learning_rate": 7.360544217687076e-07,
      "loss": 0.0,
      "step": 6910
    },
    {
      "epoch": 9.276370954217676,
      "grad_norm": 0.0006346456939354539,
      "learning_rate": 7.224489795918368e-07,
      "loss": 0.0,
      "step": 6920
    },
    {
      "epoch": 9.289787019956398,
      "grad_norm": 0.0005150482757017016,
      "learning_rate": 7.08843537414966e-07,
      "loss": 0.0,
      "step": 6930
    },
    {
      "epoch": 9.30320308569512,
      "grad_norm": 0.0007885785889811814,
      "learning_rate": 6.952380952380954e-07,
      "loss": 0.0,
      "step": 6940
    },
    {
      "epoch": 9.316619151433843,
      "grad_norm": 0.004316138569265604,
      "learning_rate": 6.816326530612245e-07,
      "loss": 0.0,
      "step": 6950
    },
    {
      "epoch": 9.330035217172565,
      "grad_norm": 0.0011926110601052642,
      "learning_rate": 6.680272108843539e-07,
      "loss": 0.0,
      "step": 6960
    },
    {
      "epoch": 9.343451282911285,
      "grad_norm": 0.002468172227963805,
      "learning_rate": 6.54421768707483e-07,
      "loss": 0.0,
      "step": 6970
    },
    {
      "epoch": 9.356867348650008,
      "grad_norm": 0.0005406058044172823,
      "learning_rate": 6.408163265306124e-07,
      "loss": 0.0,
      "step": 6980
    },
    {
      "epoch": 9.37028341438873,
      "grad_norm": 0.0020151822827756405,
      "learning_rate": 6.272108843537415e-07,
      "loss": 0.0,
      "step": 6990
    },
    {
      "epoch": 9.383699480127452,
      "grad_norm": 0.0025700631085783243,
      "learning_rate": 6.136054421768707e-07,
      "loss": 0.0,
      "step": 7000
    },
    {
      "epoch": 9.397115545866175,
      "grad_norm": 0.0011762408539652824,
      "learning_rate": 6.000000000000001e-07,
      "loss": 0.0,
      "step": 7010
    },
    {
      "epoch": 9.410531611604897,
      "grad_norm": 0.0007699385168962181,
      "learning_rate": 5.863945578231293e-07,
      "loss": 0.0,
      "step": 7020
    },
    {
      "epoch": 9.42394767734362,
      "grad_norm": 0.0006875322433188558,
      "learning_rate": 5.727891156462586e-07,
      "loss": 0.0,
      "step": 7030
    },
    {
      "epoch": 9.437363743082342,
      "grad_norm": 0.0006738902302458882,
      "learning_rate": 5.591836734693878e-07,
      "loss": 0.0,
      "step": 7040
    },
    {
      "epoch": 9.450779808821062,
      "grad_norm": 0.0011230247328057885,
      "learning_rate": 5.45578231292517e-07,
      "loss": 0.0,
      "step": 7050
    },
    {
      "epoch": 9.464195874559785,
      "grad_norm": 0.000503784860484302,
      "learning_rate": 5.319727891156463e-07,
      "loss": 0.0,
      "step": 7060
    },
    {
      "epoch": 9.477611940298507,
      "grad_norm": 0.0006306846044026315,
      "learning_rate": 5.183673469387755e-07,
      "loss": 0.0,
      "step": 7070
    },
    {
      "epoch": 9.49102800603723,
      "grad_norm": 0.00085480633424595,
      "learning_rate": 5.047619047619048e-07,
      "loss": 0.0,
      "step": 7080
    },
    {
      "epoch": 9.504444071775952,
      "grad_norm": 0.0010025011142715812,
      "learning_rate": 4.91156462585034e-07,
      "loss": 0.0,
      "step": 7090
    },
    {
      "epoch": 9.517860137514674,
      "grad_norm": 0.0009898958960548043,
      "learning_rate": 4.775510204081632e-07,
      "loss": 0.0,
      "step": 7100
    },
    {
      "epoch": 9.531276203253396,
      "grad_norm": 0.0008763425867073238,
      "learning_rate": 4.6394557823129253e-07,
      "loss": 0.0,
      "step": 7110
    },
    {
      "epoch": 9.544692268992119,
      "grad_norm": 0.00042326137190684676,
      "learning_rate": 4.503401360544218e-07,
      "loss": 0.0,
      "step": 7120
    },
    {
      "epoch": 9.55810833473084,
      "grad_norm": 0.0005191833479329944,
      "learning_rate": 4.3673469387755107e-07,
      "loss": 0.0,
      "step": 7130
    },
    {
      "epoch": 9.571524400469562,
      "grad_norm": 0.0008377199992537498,
      "learning_rate": 4.2312925170068036e-07,
      "loss": 0.0,
      "step": 7140
    },
    {
      "epoch": 9.584940466208284,
      "grad_norm": 0.0007517491467297077,
      "learning_rate": 4.095238095238096e-07,
      "loss": 0.0,
      "step": 7150
    },
    {
      "epoch": 9.598356531947006,
      "grad_norm": 0.002475888002663851,
      "learning_rate": 3.9591836734693884e-07,
      "loss": 0.0,
      "step": 7160
    },
    {
      "epoch": 9.611772597685729,
      "grad_norm": 0.0006755446665920317,
      "learning_rate": 3.823129251700681e-07,
      "loss": 0.0,
      "step": 7170
    },
    {
      "epoch": 9.625188663424451,
      "grad_norm": 0.0009685784461908042,
      "learning_rate": 3.687074829931973e-07,
      "loss": 0.0,
      "step": 7180
    },
    {
      "epoch": 9.638604729163173,
      "grad_norm": 0.0005077888490632176,
      "learning_rate": 3.5510204081632656e-07,
      "loss": 0.0,
      "step": 7190
    },
    {
      "epoch": 9.652020794901896,
      "grad_norm": 0.0008089074399322271,
      "learning_rate": 3.4149659863945585e-07,
      "loss": 0.0,
      "step": 7200
    },
    {
      "epoch": 9.665436860640618,
      "grad_norm": 0.00037011379026807845,
      "learning_rate": 3.278911564625851e-07,
      "loss": 0.0,
      "step": 7210
    },
    {
      "epoch": 9.678852926379339,
      "grad_norm": 0.001273202826268971,
      "learning_rate": 3.1428571428571433e-07,
      "loss": 0.0,
      "step": 7220
    },
    {
      "epoch": 9.692268992118061,
      "grad_norm": 0.0004550964804366231,
      "learning_rate": 3.0068027210884357e-07,
      "loss": 0.0,
      "step": 7230
    },
    {
      "epoch": 9.705685057856783,
      "grad_norm": 0.0031661204993724823,
      "learning_rate": 2.870748299319728e-07,
      "loss": 0.0,
      "step": 7240
    },
    {
      "epoch": 9.719101123595506,
      "grad_norm": 0.001270122593268752,
      "learning_rate": 2.7346938775510205e-07,
      "loss": 0.0,
      "step": 7250
    },
    {
      "epoch": 9.732517189334228,
      "grad_norm": 0.0006510174716822803,
      "learning_rate": 2.5986394557823135e-07,
      "loss": 0.0,
      "step": 7260
    },
    {
      "epoch": 9.74593325507295,
      "grad_norm": 0.0012256077025085688,
      "learning_rate": 2.462585034013606e-07,
      "loss": 0.0,
      "step": 7270
    },
    {
      "epoch": 9.759349320811673,
      "grad_norm": 0.0014280725736171007,
      "learning_rate": 2.3265306122448983e-07,
      "loss": 0.0,
      "step": 7280
    },
    {
      "epoch": 9.772765386550393,
      "grad_norm": 0.0009068111539818347,
      "learning_rate": 2.1904761904761907e-07,
      "loss": 0.0,
      "step": 7290
    },
    {
      "epoch": 9.786181452289116,
      "grad_norm": 0.0014013091567903757,
      "learning_rate": 2.0544217687074833e-07,
      "loss": 0.0,
      "step": 7300
    },
    {
      "epoch": 9.799597518027838,
      "grad_norm": 0.0015790577745065093,
      "learning_rate": 1.9183673469387757e-07,
      "loss": 0.0,
      "step": 7310
    },
    {
      "epoch": 9.81301358376656,
      "grad_norm": 0.000854775367770344,
      "learning_rate": 1.7823129251700684e-07,
      "loss": 0.0,
      "step": 7320
    },
    {
      "epoch": 9.826429649505283,
      "grad_norm": 0.0007099539507180452,
      "learning_rate": 1.6462585034013608e-07,
      "loss": 0.0,
      "step": 7330
    },
    {
      "epoch": 9.839845715244005,
      "grad_norm": 0.0011450703023001552,
      "learning_rate": 1.5102040816326532e-07,
      "loss": 0.0,
      "step": 7340
    },
    {
      "epoch": 9.853261780982727,
      "grad_norm": 0.0006163731450214982,
      "learning_rate": 1.3741496598639459e-07,
      "loss": 0.0,
      "step": 7350
    },
    {
      "epoch": 9.86667784672145,
      "grad_norm": 0.0002998432028107345,
      "learning_rate": 1.2380952380952383e-07,
      "loss": 0.0,
      "step": 7360
    },
    {
      "epoch": 9.880093912460172,
      "grad_norm": 0.0004699374840129167,
      "learning_rate": 1.1020408163265308e-07,
      "loss": 0.0,
      "step": 7370
    },
    {
      "epoch": 9.893509978198892,
      "grad_norm": 0.002000143053010106,
      "learning_rate": 9.659863945578232e-08,
      "loss": 0.0,
      "step": 7380
    },
    {
      "epoch": 9.906926043937615,
      "grad_norm": 0.0035296764690428972,
      "learning_rate": 8.299319727891157e-08,
      "loss": 0.0,
      "step": 7390
    },
    {
      "epoch": 9.920342109676337,
      "grad_norm": 0.0006676933844573796,
      "learning_rate": 6.938775510204083e-08,
      "loss": 0.0,
      "step": 7400
    },
    {
      "epoch": 9.93375817541506,
      "grad_norm": 0.000647395325358957,
      "learning_rate": 5.578231292517007e-08,
      "loss": 0.0,
      "step": 7410
    },
    {
      "epoch": 9.947174241153782,
      "grad_norm": 0.0007615272188559175,
      "learning_rate": 4.217687074829932e-08,
      "loss": 0.0,
      "step": 7420
    },
    {
      "epoch": 9.960590306892504,
      "grad_norm": 0.0013128157006576657,
      "learning_rate": 2.8571428571428575e-08,
      "loss": 0.0,
      "step": 7430
    },
    {
      "epoch": 9.974006372631226,
      "grad_norm": 0.000707906496245414,
      "learning_rate": 1.4965986394557825e-08,
      "loss": 0.0,
      "step": 7440
    },
    {
      "epoch": 9.987422438369949,
      "grad_norm": 0.0009185499511659145,
      "learning_rate": 1.360544217687075e-09,
      "loss": 0.0,
      "step": 7450
    }
  ],
  "logging_steps": 10,
  "max_steps": 7450,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.121270258724045e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
